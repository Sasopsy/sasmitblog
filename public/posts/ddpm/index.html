<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>The Math of DDPMs | Sasmit&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="Introduction This blog post dives deep into the mathematics behind Denoising Diffusion Probabilistic Models, breaking down the objective function that make DDPMs work. I tried to &ldquo;hand-wave&rdquo; as little math as possible in this post and tried my best to cover all the steps in this derivation.
DDPMs Diffusion models are inspired by non-equilibrium thermodynamics. They define a Markov chain to slowly add random noise to data and learn to reverse the diffusion to get the original data sample back from the noise.">
<meta name="author" content="Sasmit Datta">
<link rel="canonical" href="https://example.org/posts/ddpm/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://example.org/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://example.org/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://example.org/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://example.org/apple-touch-icon.png">
<link rel="mask-icon" href="https://example.org/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://example.org/posts/ddpm/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="The Math of DDPMs" />
<meta property="og:description" content="Introduction This blog post dives deep into the mathematics behind Denoising Diffusion Probabilistic Models, breaking down the objective function that make DDPMs work. I tried to &ldquo;hand-wave&rdquo; as little math as possible in this post and tried my best to cover all the steps in this derivation.
DDPMs Diffusion models are inspired by non-equilibrium thermodynamics. They define a Markov chain to slowly add random noise to data and learn to reverse the diffusion to get the original data sample back from the noise." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://example.org/posts/ddpm/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-04-24T18:47:49+05:30" />
<meta property="article:modified_time" content="2024-04-24T18:47:49+05:30" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="The Math of DDPMs"/>
<meta name="twitter:description" content="Introduction This blog post dives deep into the mathematics behind Denoising Diffusion Probabilistic Models, breaking down the objective function that make DDPMs work. I tried to &ldquo;hand-wave&rdquo; as little math as possible in this post and tried my best to cover all the steps in this derivation.
DDPMs Diffusion models are inspired by non-equilibrium thermodynamics. They define a Markov chain to slowly add random noise to data and learn to reverse the diffusion to get the original data sample back from the noise."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://example.org/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "The Math of DDPMs",
      "item": "https://example.org/posts/ddpm/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "The Math of DDPMs",
  "name": "The Math of DDPMs",
  "description": "Introduction This blog post dives deep into the mathematics behind Denoising Diffusion Probabilistic Models, breaking down the objective function that make DDPMs work. I tried to \u0026ldquo;hand-wave\u0026rdquo; as little math as possible in this post and tried my best to cover all the steps in this derivation.\nDDPMs Diffusion models are inspired by non-equilibrium thermodynamics. They define a Markov chain to slowly add random noise to data and learn to reverse the diffusion to get the original data sample back from the noise.",
  "keywords": [
    
  ],
  "articleBody": "Introduction This blog post dives deep into the mathematics behind Denoising Diffusion Probabilistic Models, breaking down the objective function that make DDPMs work. I tried to “hand-wave” as little math as possible in this post and tried my best to cover all the steps in this derivation.\nDDPMs Diffusion models are inspired by non-equilibrium thermodynamics. They define a Markov chain to slowly add random noise to data and learn to reverse the diffusion to get the original data sample back from the noise. The idea is to generate images from noise by iteratively removing “noise” from it.\nForward Diffusion Process Given a sample datapoint $\\mathbf{x}_0\\sim q(\\mathbf{x})$, forward diffusion process is addition of small amounts of gaussian noise to sample in $T$ time-steps, producing a sequence of noisy samples $\\mathbf{x}_1,…\\mathbf{x}_T$ controlled a by a variance schedule \\(\\{\\beta_t\\in(0,1)\\}_{t=1}^{T}\\).\n$$\\boxed{q(\\mathbf{x}_t|\\mathbf{x}_{t-1})=\\mathcal{N}(\\mathbf{x}_t|\\sqrt{1-\\beta_t}\\mathbf{x}_{t-1},\\beta_t\\mathbf{I})} \\tag{1}$$ $$q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)=\\prod_{t=1}^{T}q(\\mathbf{x}_t|\\mathbf{x}_{t-1}) \\tag{2}$$ The data sample loses its features and becomes more noisy as it propagates through the forward process.\nResult 1 As $T\\rightarrow \\infty$, $\\mathbf{x}_T$ is equivalent to an isotropic Gaussian.\nProof. Let us assume a constant schedule: $$\\beta_t=\\beta$$ We know, $$q(\\mathbf{x}_T|\\mathbf{x}_{T-1})=\\mathcal{N}(\\mathbf{x}_T|\\sqrt{1-\\beta}\\mathbf{x}_{T-1},\\beta\\mathbf{I})$$ According to the re-parametrisation trick, $$\\mathbf{x}_T=\\sqrt{1-\\beta}\\mathbf{x}_{T-1}+\\sqrt{\\beta}\\mathcal{N}(\\mathbf{0},\\mathbf{I})$$ Therefore expanding on this, $$ \\begin{aligned} \u0026\\mathbf{x}_T=\\sqrt{1-\\beta}\\mathbf{x}_{T-1}+\\sqrt{\\beta}\\mathcal{N}(\\mathbf{0},\\mathbf{I})\\\\ \u0026\\mathbf{x}_T= \\sqrt{1-\\beta}(\\sqrt{1-\\beta}\\mathbf{x}_{T-2}+\\sqrt{\\beta}\\mathcal{N}(\\mathbf{0},\\mathbf{I})) + \\sqrt{\\beta}\\mathcal{N}(\\mathbf{0},\\mathbf{I})\\\\ \u0026\\mathbf{x}_T=\\sqrt{1-\\beta}^2\\mathbf{x}_{T-2}+\\sqrt{1-\\beta}\\sqrt{\\beta}\\mathcal{N}(\\mathbf{0},\\mathbf{I}) +\\sqrt{\\beta}\\mathcal{N}(\\mathbf{0},\\mathbf{I})\\\\ \u0026\\mathbf{x}_T=\\sqrt{1-\\beta}^2(\\sqrt{1-\\beta}\\mathbf{x}_{T-3}+\\sqrt{\\beta}\\mathcal{N}(\\mathbf{0},\\mathbf{I}))+\\sqrt{1-\\beta}\\sqrt{\\beta}\\mathcal{N}(\\mathbf{0},\\mathbf{I}) +\\sqrt{\\beta}\\mathcal{N}(\\mathbf{0},\\mathbf{I})\\\\ \u0026\\mathbf{x}_T=\\sqrt{1-\\beta}^T\\mathbf{x}_{0}+\\sqrt{1-\\beta}^{T-1}\\sqrt{\\beta}\\mathcal{N}(\\mathbf{0},\\mathbf{I}) +...+\\sqrt{1-\\beta}\\sqrt{\\beta}+\\sqrt{\\beta}\\mathcal{N}(\\mathbf{0},\\mathbf{I})\\\\ \u0026\\mathbf{x}_T=\\sqrt{1-\\beta}^T\\mathbf{x}_{0}+\\mathcal{N}(\\mathbf{0},\\mathbf{I})(\\sqrt{1-\\beta}^{T-1}\\sqrt{\\beta} +...+\\sqrt{1-\\beta}\\sqrt{\\beta}+\\sqrt{\\beta})\\\\ \\end{aligned}$$ The second term is GP sum with a common ratio $\\sqrt{1-\\beta}$. Therefore, $$\\mathbf{x}_T=\\sqrt{1-\\beta}^T\\mathbf{x}_{0}+\\sqrt\\beta\\frac{1-\\sqrt{1-\\beta}^{T-1}}{1-\\sqrt{1-\\beta}}\\mathcal{N}(\\mathbf{0},\\mathbf{I})$$ Since, $\\beta«1$ and $T\\rightarrow\\infty$, $$\\mathbf{x}_T\\approx\\mathcal{N}(\\mathbf{0},\\mathbf{I})$$ One-Shot Forward Diffusion Instead of performing the forward diffusion process $T$ times, we can formulate an equation that can compute it at a single go.\nLet us assume, $$\\boxed{\\alpha_t=1-\\beta_t}\\tag{3}$$ Therefore, we can write our forward process of $t$-th step as $$\\mathbf{x}_t=\\sqrt{\\alpha_t}\\mathbf{x}_{t-1}+\\sqrt{1-\\alpha_t}\\epsilon_t$$ where, $\\epsilon_t\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})$. Noise from all time-steps are samples from a normal distribution.\nExpanding on this, $$ \\begin{aligned} \u0026\\mathbf{x}_t=\\sqrt{\\alpha_t}\\mathbf{x}_{t-1}+ \\sqrt{1-\\alpha_t}\\epsilon_t \\\\ \u0026\\mathbf{x}_t=\\sqrt{\\alpha_t}(\\sqrt{\\alpha_{t-1}}\\mathbf{x}_{t-2}+ \\sqrt{1-\\alpha_{t-1}}\\epsilon_{t-1})+ \\sqrt{1-\\alpha_t}\\epsilon_t \\\\ \u0026\\mathbf{x}_t=\\sqrt{\\alpha_t}\\sqrt{\\alpha_{t-1}}\\mathbf{x}_{t-2}+ \\sqrt{\\alpha_t}\\sqrt{1-\\alpha_{t-1}}\\epsilon_{t-1}+ \\sqrt{1-\\alpha_t}\\epsilon_t \\\\ \\end{aligned} $$ Now, we know that when $$ \\begin{aligned} \u0026X\\sim N(\\mu_{X},\\sigma_{X}^{2})\\\\ \u0026Y\\sim N(\\mu_{Y},\\sigma_{Y}^{2})\\\\ \u0026Z=X+Y\\\\ \\end{aligned} $$ Then, $$Z\\sim N(\\mu_{X}+\\mu_{Y},\\sigma _{X}^{2}+\\sigma_{Y}^{2})$$ So, $$\\sqrt{\\alpha_t}\\sqrt{1-\\alpha_{t-1}}\\epsilon_{t-1}+ \\sqrt{1-\\alpha_t}\\epsilon_t=\\sqrt{\\alpha_t(1-\\alpha_{t-1})+1-\\alpha_t}\\epsilon$$ And hence, coming back to our formulation $$\\begin{aligned} \u0026\\mathbf{x}_t=\\sqrt{\\alpha_t}\\sqrt{\\alpha_{t-1}}\\mathbf{x}_{t-2}+ \\sqrt{\\alpha_t-\\alpha_t\\alpha_{t-1}+1-\\alpha_t}\\epsilon \\\\ \u0026\\mathbf{x}_t=\\sqrt{\\alpha_t\\alpha_{t-1}}\\mathbf{x}_{t-2}+ \\sqrt{1-\\alpha_t\\alpha_{t-1}}\\epsilon \\\\ \\end{aligned} $$ If we keep iteratively doing this, we arrive at a formula, $$ \\mathbf{x}_t=\\sqrt{\\alpha_t\\alpha_{t-1}...\\alpha_2\\alpha_1}\\mathbf{x}_{0}+ \\sqrt{1-\\alpha_t\\alpha_{t-1}...\\alpha_2\\alpha_1}\\epsilon \\\\ $$ Let, $$\\boxed{\\bar{\\alpha}_t=\\prod_{i=1}^{t}\\alpha_i}\\tag{4}$$ Finally, $$\\boxed{ \\mathbf{x}_t=\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_{0}+ \\sqrt{1-\\bar{\\alpha}_t}\\epsilon} \\tag{5}\\\\ $$ Reverse Diffusion Process Through the reverse diffusion process, we want to sample from \\(q(\\mathbf{x}_{t-1}|\\mathbf{x}_{t})\\) to able to recreate the original image from a Gaussian noise $\\mathbf{x}_T\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})$.\nUnfortunately, we cannot compute \\(q(\\mathbf{x}_{t-1}|\\mathbf{x}_{t})\\) as it requires the entire data distribution to compute.\nSo we learn a model $p_\\theta$ to approximate these conditional probabilities. $$p_\\theta(\\mathbf{x}_{0:T})=p_\\theta(\\mathbf{x}_T)\\prod_{t=1}^{T}p_\\theta(\\mathbf{x}_{t-1}|\\mathbf{x}_{t}) \\tag{6}$$ We model our approximate reverse diffusion process parametrising the mean and variance of the noise to be estimated. We assume it is a normal distribution. $$p_\\theta(\\mathbf{x}_{t-1}|\\mathbf{x}_{t})=\\mathcal{N}(\\mathbf{x}_{t-1}|\\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t,t),\\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t,t))$$ This kind of setup is very similar to a VAE where we want to maximise $$\\log p_\\theta(\\mathbf{x}_0)$$ Hence, $$\\begin{aligned} \\log p_\\theta(\\mathbf{x}_0) \u0026= \\log p_\\theta(\\mathbf{x}_0)\\cdot \\int q(\\mathbf{x}_{1:T}|\\mathbf{x}_0) d\\mathbf{x}_{1:T}\\\\ \u0026= \\int \\log p_\\theta(\\mathbf{x}_0) q(\\mathbf{x}_{1:T}|\\mathbf{x}_0) d\\mathbf{x}_{1:T}\\\\ \u0026=\\mathbb{E}_{q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)} \\left[ \\log p_\\theta(\\mathbf{x}_0) \\right] \\end{aligned}$$ Now the term \\(\\mathbb{E}_{q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)}[ \\log p_\\theta(\\mathbf{x}_0)]\\) can be further be broken down using Bayes rule. So from $(2)$ and $(6)$ $$\\mathbb{E}_{q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)} \\left[ \\log \\frac{p_\\theta(\\mathbf{x}_{0:T})}{q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)} \\right] \\tag{7} $$ Eq $(7)$ is for a single point in our dataset. We want to find the expectation of the likelihood over the entire distribution, $$\\mathbb{E}_{q(\\mathbf{x}_0)}\\left[ \\mathbb{E}_{q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)} \\left[ \\log \\frac{p_\\theta(\\mathbf{x}_{0:T})}{q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)} \\right] \\right] $$ which can be written as $$\\int\\int\\log \\frac{p_\\theta(\\mathbf{x}_{0:T})}{q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)}q(\\mathbf{x}_{1:T}|\\mathbf{x}_0) d\\mathbf{x}_{1:T}\\cdot q(\\mathbf{x}_0)d\\mathbf{x}_0$$ Since \\(q(\\mathbf{x}_{0:T})=q(\\mathbf{x}_0)q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)\\), our final log-likelihood can be written as $$ \\mathbb{E}_{q(\\mathbf{x}_{0:T})} \\left[ \\log \\frac{p_\\theta(\\mathbf{x}_{0:T})}{q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)} \\right] \\tag{8} $$ Maximising eq $(8)$ is equivalent to minimising: $$ \\mathbb{E}_{q(\\mathbf{x}_{0:T})} \\left[ \\log \\frac{q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{0:T})} \\right] = \\mathcal{L}_{\\text{VLB}}\\tag{8} $$ Simplifying the Likelihood So taking the \\(\\mathcal{L}_{\\text{VLB}}\\), $$ \\begin{align} \u0026= \\mathbb{E}_{q} \\left[ \\log \\frac{q(\\mathbf{x}_T | \\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_T)} + \\sum_{t=2}^{T} \\log \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)} - \\log p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1) \\right] \\\\ \u0026= \\mathbb{E}_{q} \\left[ D_{KL}(q(\\mathbf{x}_T | \\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_T)) + \\sum_{t=2}^{T} D_{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)) - \\log p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1) \\right] \\end{align} $$ $$\\begin{align} \\mathcal{L}_{\\text{VLB}} \u0026= \\mathbb{E}_{q(\\mathbf{x}_{0:T})} \\left[ \\log \\frac{q(\\mathbf{x}_{1:T} | \\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{0:T})} \\right] \\\\ \\end{align}$$ So expanding using $(6)$ an $(2)$ and taking \\(q=q(\\mathbf{x}_{0:T}) \\) $$\\begin{aligned} \u0026\\mathbb{E}_{q} \\left[ \\log \\frac{\\prod_{t=1}^{T} q(\\mathbf{x}_t | \\mathbf{x}_{t-1})}{p_\\theta(\\mathbf{x}_T) \\prod_{t=1}^{T} p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)} \\right]\\\\ =\u0026 \\mathbb{E}_{q} \\left[ - \\log p_\\theta(\\mathbf{x}_T) + \\sum_{t=1}^{T} \\log \\frac{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})}{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)} \\right] \\\\ \\end{aligned}$$ Now separating the summation (starting it from $t=2$ and stripping out $t=1$) $$\\begin{aligned} \\mathbb{E}_{q} \\left[ - \\log p_\\theta(\\mathbf{x}_T) + \\sum_{t=2}^{T} \\log \\frac{q(\\mathbf{x}_{t} | \\mathbf{x}_{t-1}, \\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)} + \\log \\frac{q(\\mathbf{x}_1 | \\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1)} \\right] \\\\ \\end{aligned}$$ Note that \\(q(\\mathbf{x}_{t} | \\mathbf{x}_{t-1})=q(\\mathbf{x}_{t} | \\mathbf{x}_{t-1},\\mathbf{x}_0)\\) as $q$ is a Markov chain. Conditioning it on \\(\\mathbf{x}_0\\) won’t change anything. Now focusing on the summation, using Bayes rule, we get $$ \\begin{aligned} \u0026\\mathbb{E}_{q} \\left[ - \\log p_\\theta(\\mathbf{x}_T) + \\sum_{t=2}^{T} \\log \\left( \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)} \\cdot \\frac{q(\\mathbf{x}_t | \\mathbf{x}_0)}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)} \\right) + \\log \\frac{q(\\mathbf{x}_1 | \\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1)} \\right]\\\\ =\u0026\\mathbb{E}_{q} \\left[ - \\log p_\\theta(\\mathbf{x}_T) + \\sum_{t=2}^{T} \\log \\frac{q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)} + \\sum_{t=2}^{T} \\log \\frac{q(\\mathbf{x}_t | \\mathbf{x}_0)}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)} + \\log \\frac{q(\\mathbf{x}_1 | \\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1)} \\right] \\\\ \\end{aligned}$$ Now observing the term $$\\sum_{t=2}^{T} \\log \\frac{q(\\mathbf{x}_t | \\mathbf{x}_0)}{q(\\mathbf{x}_{t-1} | \\mathbf{x}_0)}=\\frac{q(\\mathbf{x}_2| \\mathbf{x}_0)...q(\\mathbf{x}_{T-1} | \\mathbf{x}_0)q(\\mathbf{x}_T | \\mathbf{x}_0)}{q(\\mathbf{x}_1 | \\mathbf{x}_0)q(\\mathbf{x}_2 | \\mathbf{x}_0)...q(\\mathbf{x}_{T-1} | \\mathbf{x}_0)}$$ There’s clear recursive cancellation that takes place leaving us with our final term $$\\log\\frac{q(\\mathbf{x}_T | \\mathbf{x}_0)}{q(\\mathbf{x}_1 | \\mathbf{x}_0)}$$ Therefore plugging it back into our $\\mathcal{L}_{\\text{VLB}}$ $$ \\begin{align*} \u0026\\mathbb{E}_q \\left[ - \\log p_\\theta(\\mathbf{x}_T) + \\sum_{t=2}^{T} \\log \\frac{q(\\mathbf{x}_{t-1}|\\mathbf{x}_t, \\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{t-1}|\\mathbf{x}_t)} + \\log \\frac{q(\\mathbf{x}_T|\\mathbf{x}_0)}{q(\\mathbf{x}_1|\\mathbf{x}_0)} + \\log \\frac{q(\\mathbf{x}_1|\\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_0|\\mathbf{x}_1)} \\right] \\\\ =\u0026\\mathbb{E}_q \\left[ \\log \\frac{q(\\mathbf{x}_T|\\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_T)} + \\sum_{t=2}^{T} \\log \\frac{q(\\mathbf{x}_{t-1}|\\mathbf{x}_t, \\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{t-1}|\\mathbf{x}_t)} - \\log p_\\theta(\\mathbf{x}_0|\\mathbf{x}_1) \\right] \\\\ =\u0026\\mathbb{E}_q \\left[ D_{KL}(q(\\mathbf{x}_T|\\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_T)) + \\sum_{t=2}^{T} D_{KL}(q(\\mathbf{x}_{t-1}|\\mathbf{x}_t, \\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1}|\\mathbf{x}_t)) - \\log p_\\theta(\\mathbf{x}_0|\\mathbf{x}_1) \\right] \\end{align*} $$ Let us divide the final term into smaller chunks\n\\(L_T=D_{KL}(q(\\mathbf{x}_T | \\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_T))\\) \\(L_{t}=D_{KL}(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t))\\) where \\(2\\leq t \\leq T-1\\) \\(L_0=\\log p_\\theta(\\mathbf{x}_0 | \\mathbf{x}_1)\\) PDF of of $L_t$ We have the general term for a reverse diffusion process: $$q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0)$$ This is a tractable expression as we have the reverse process being conditioned on $\\mathbf{x}_0$ - a single datapoint and not the entire data distribution.\nUsing Bayes theorem, we can write this as: $$q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0)=\\frac{q(\\mathbf{x}_{t}|\\mathbf{x}_{t-1},\\mathbf{x}_{0})q(\\mathbf{x}_{t-1}|\\mathbf{x}_{0})}{q(\\mathbf{x}_{t}|\\mathbf{x}_{0})}$$ For our forward process, \\(q(\\mathbf{x}_{t}|\\mathbf{x}_{t-1},\\mathbf{x}_{0})\\) is a Markov chain, hence, \\(q(\\mathbf{x}_{t}|\\mathbf{x}_{t-1},\\mathbf{x}_{0})=q(\\mathbf{x}_{t}|\\mathbf{x}_{t-1})\\). So our given pdfs can easily be written expressions we already have. \\(q(\\mathbf{x}_{t}|\\mathbf{x}_{0})\\) and \\((\\mathbf{x}_{t-1}|\\mathbf{x}_{0})\\) is equation $(5)$. $$q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0)=\\frac{\\mathcal{N}(\\mathbf{x}_{t}|\\sqrt{\\alpha_t}\\mathbf{x}_{t-1},(1-\\alpha_t)\\mathbf{I}) \\mathcal{N}(\\mathbf{x}_{t-1}|\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_{0},(1-\\bar{\\alpha}_{t-1})\\mathbf{I})}{\\mathcal{N}(\\mathbf{x}_{t}|\\sqrt{\\bar{\\alpha}_{t}}\\mathbf{x}_{0},(1-\\bar{\\alpha}_{t})\\mathbf{I})}$$ Our goal is to find a gaussian pdf with mean a function of \\(\\mathbf{x}_t\\) and \\( \\mathbf{x}_0 \\) (during training we’ll have access to both values). So expanding the above and take only the exponential terms, we get $$\\exp\\left(-\\frac{1}{2}\\left[\\frac{(\\mathbf{x}_t - \\sqrt{\\alpha_t}\\mathbf{x}_{t-1})^2}{1-\\alpha_t} + \\frac{(\\mathbf{x}_{t-1} - \\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0)^2}{1-\\bar{\\alpha}_{t-1}} - \\frac{(\\mathbf{x}_t - \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0)^2}{1-\\bar{\\alpha}_t}\\right]\\right) $$ Our first strategy will be to take all the $\\mathbf{x}_{t-1}$ terms and group them together. So, we expand the above terms:\n\\(\\frac{(\\mathbf{x}_t - \\sqrt{\\alpha_t}\\mathbf{x}_{t-1})^2}{1-\\alpha_t} = \\frac{\\mathbf{x}_t^2 - 2\\mathbf{x}_t\\sqrt{\\alpha_t}\\mathbf{x}_{t-1} + \\alpha_t \\mathbf{x}_{t-1}^2}{1-\\alpha_t}\\) \\(\\frac{(\\mathbf{x}_{t-1} - \\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0)^2}{1-\\bar{\\alpha}_{t-1}} = \\frac{\\mathbf{x}_{t-1}^2 - 2\\mathbf{x}_{t-1}\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0 + \\bar{\\alpha}_{t-1} \\mathbf{x}_0^2}{1-\\bar{\\alpha}_{t-1}}\\) \\(\\frac{(\\mathbf{x}_t - \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0)^2}{1-\\bar{\\alpha}_t} = \\frac{\\mathbf{x}_t^2 - 2\\mathbf{x}_t\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\bar{\\alpha}_t \\mathbf{x}_0^2}{1-\\bar{\\alpha}_t}\\) Now we separate the the \\(\\mathbf{x}_{t-1}\\) terms and the rest. The \\( \\mathbf{x}_{t-1}\\) terms in the exponential are $$\\begin{aligned} \u0026\\mathbf{x}_{t-1}^2 \\left( \\frac{1-\\bar{\\alpha}_t}{(1 - \\alpha_t)(1 - \\bar{\\alpha}_{t-1})} \\right) - 2\\mathbf{x}_{t-1} \\left( \\frac{\\sqrt{\\alpha_t}\\mathbf{x}_t}{1 - \\alpha_t} + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0}{1 - \\bar{\\alpha}_{t-1}} \\right)\\\\ =\u0026\\mathbf{x}_{t-1}^2 \\left( \\frac{1-\\bar{\\alpha}_t}{(1 - \\alpha_t)(1 - \\bar{\\alpha}_{t-1})} \\right) - 2\\mathbf{x}_{t-1} \\left( \\frac{(1-\\bar{\\alpha}_{t-1})\\sqrt{\\alpha_t}\\mathbf{x}_t+(1 - \\alpha_t)\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0}{(1 - \\bar{\\alpha}_{t-1})(1 - \\alpha_t)}\\right)\\\\ =\u0026 f(\\mathbf{x}_{t-1}) \\end{aligned} $$ The rest are $$\\begin{aligned} \u0026\\frac{\\mathbf{x}_t^2}{1 - \\alpha_t} + \\frac{\\bar{\\alpha}_{t-1} \\mathbf{x}_0^2}{1 - \\bar{\\alpha}_{t-1}} - \\frac{\\mathbf{x}_t^2}{1 - \\bar{\\alpha}_t} - \\frac{\\bar{\\alpha}_t \\mathbf{x}_0^2}{1 - \\bar{\\alpha}_t} + \\frac{2\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0\\mathbf{x}_t}{1 - \\bar{\\alpha}_t}\\\\ =\u0026 \\frac{1-\\bar{\\alpha_t}-1+\\alpha_t}{(1-\\bar{\\alpha_t})(1-\\alpha_t)}\\mathbf{x}_t^2 + \\frac{\\bar{\\alpha}_{t-1}-\\bar{\\alpha}_{t-1}\\bar{\\alpha}_{t}-\\bar{\\alpha}_{t}+\\bar{\\alpha}_{t-1}\\bar{\\alpha}_{t}}{(1-\\bar{\\alpha}_{t-1})(1-\\bar{\\alpha}_{t})}\\mathbf{x}_0^2 + \\frac{2\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0\\mathbf{x}_t}{1 - \\bar{\\alpha}_t}\\\\ =\u0026 \\frac{\\alpha_t-\\bar{\\alpha_t}}{(1-\\bar{\\alpha_t})(1-\\alpha_t)}\\mathbf{x}_t^2 + \\frac{\\bar{\\alpha}_{t-1}-\\bar{\\alpha}_{t}}{(1-\\bar{\\alpha}_{t-1})(1-\\bar{\\alpha}_{t})}\\mathbf{x}_0^2+\\frac{2\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0\\mathbf{x}_t}{1 - \\bar{\\alpha}_t}\\\\ =\u0026\\frac{\\alpha_t(1-\\bar{\\alpha}_{t-1})}{(1-\\bar{\\alpha_t})(1-\\alpha_t)}\\mathbf{x}_t^2 + \\frac{\\bar{\\alpha}_{t-1}(1-\\alpha_t)}{(1-\\bar{\\alpha}_{t-1})(1-\\bar{\\alpha}_{t})}\\mathbf{x}_0^2+\\frac{2\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0\\mathbf{x}_t}{1 - \\bar{\\alpha}_t}\\\\ \\end{aligned}$$ The above is a squared sum. Hence, it can be written as $$\\begin{aligned} \u0026\\frac{1}{1-\\bar{\\alpha}_t}\\left(\\sqrt{\\frac{\\alpha_t(1-\\bar{\\alpha}_{t-1})}{1-\\alpha_t}}\\mathbf{x}_t + \\sqrt{\\frac{\\bar{\\alpha}_{t-1}(1-\\alpha_t)}{1-\\bar{\\alpha}_{t-1}}}\\mathbf{x}_0 \\right)^2\\\\ =\u0026 \\frac{1}{(1-\\bar{\\alpha}_t)(1 - \\bar{\\alpha}_{t-1})(1 - \\alpha_t)}\\left((1-\\bar{\\alpha}_{t-1})\\sqrt{\\alpha_t}\\mathbf{x}_t+(1 - \\alpha_t)\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0 \\right)^2\\\\ =\u0026f(\\mathbf{x}_{t},\\mathbf{x}_0) \\end{aligned}$$ We want our \\(\\mathbf{x}_{t-1}^2\\) to be separate as its the random variable we want to sample. So we common out \\(\\frac{1-\\bar{\\alpha}_t}{(1 - \\alpha_t)(1 - \\bar{\\alpha}_{t-1})}\\) from both \\(f(\\mathbf{x}_{t-1})\\) and \\(f(\\mathbf{x}_{t},\\mathbf{x}_0)\\). Therefore doing so from \\(f(\\mathbf{x}_{t-1})\\) will yield $$\\begin{aligned} \u0026\\mathbf{x}_{t-1}^2 - 2\\mathbf{x}_{t-1} \\left( \\frac{(1-\\bar{\\alpha}_{t-1})\\sqrt{\\alpha_t}\\mathbf{x}_t+(1 - \\alpha_t)\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0}{1-\\bar{\\alpha}_t}\\right)\\\\ =\u0026C(\\mathbf{x}_{t-1}) \\end{aligned}$$ and from \\(f(\\mathbf{x}_{t},\\mathbf{x}_0)\\) will yield $$\\begin{aligned} \u0026\\frac{1}{(1-\\bar{\\alpha}_t)^2}\\left((1-\\bar{\\alpha}_{t-1})\\sqrt{\\alpha_t}\\mathbf{x}_t+(1 - \\alpha_t)\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0 \\right)^2\\\\ =\u0026\\left(\\frac{(1-\\bar{\\alpha}_{t-1})\\sqrt{\\alpha_t}\\mathbf{x}_t+(1 - \\alpha_t)\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0}{(1-\\bar{\\alpha}_t)} \\right)^2 \\\\ =\u0026 C(\\mathbf{x}_t,\\mathbf{x}_0) \\end{aligned}$$ Note: the above two terms aren’t \\(f(\\mathbf{x}_{t-1})\\) and \\(f(\\mathbf{x}_{t},\\mathbf{x}_0)\\). Zooming out for a moment to our original term in the exponential, $$\\begin{aligned} \u0026\\exp\\left(-\\frac{1}{2}\\left[\\frac{(\\mathbf{x}_t - \\sqrt{\\alpha_t}\\mathbf{x}_{t-1})^2}{1-\\alpha_t} + \\frac{(\\mathbf{x}_{t-1} - \\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0)^2}{1-\\bar{\\alpha}_{t-1}} - \\frac{(\\mathbf{x}_t - \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0)^2}{1-\\bar{\\alpha}_t}\\right]\\right)\\\\ =\u0026\\exp\\left(-\\frac{1}{2}\\left[f(\\mathbf{x}_{t-1})+f(\\mathbf{x}_{t},\\mathbf{x}_0)\\right]\\right) \\\\ =\u0026 \\exp-\\frac{1}{2}\\left(\\frac{1}{\\frac{(1 - \\alpha_t)(1 - \\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}}\\left[C(\\mathbf{x}_{t-1})+C(\\mathbf{x}_{t},\\mathbf{x}_0)\\right]\\right) \\end{aligned}$$ Clearly, \\(C(\\mathbf{x}_{t-1})+C(\\mathbf{x}_{t},\\mathbf{x}_0)\\) is a squared sum. Hence, we can write the above exponential as $$\\exp-\\frac{1}{2}\\left(\\frac{1}{\\frac{(1 - \\alpha_t)(1 - \\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}}\\left[\\mathbf{x}_{t-1}-\\frac{(1-\\bar{\\alpha}_{t-1})\\sqrt{\\alpha_t}\\mathbf{x}_t+(1 - \\alpha_t)\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0}{(1-\\bar{\\alpha}_t)}\\right]^2\\right)$$ Now if we evaluate the normalisation terms of our three pdfs:\n$\\frac{1}{\\sqrt{(1-\\alpha_t)2\\pi}}$ $\\frac{1}{\\sqrt{(1-\\bar{\\alpha}_{t-1})2\\pi}}$ \\(\\frac{1}{\\sqrt{(1-\\bar{\\alpha}_{t})2\\pi}}\\) and compute the final normalisation term we get, $$\\frac{1}{\\sqrt{\\frac{(1 - \\alpha_t)(1 - \\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}2\\pi}}$$ Our final formula for $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0)$ is $$\\frac{1}{\\sqrt{\\frac{(1 - \\alpha_t)(1 - \\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}2\\pi}}\\exp-\\frac{1}{2}\\left(\\frac{1}{\\frac{(1 - \\alpha_t)(1 - \\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}}\\left[\\mathbf{x}_{t-1}-\\frac{(1-\\bar{\\alpha}_{t-1})\\sqrt{\\alpha_t}\\mathbf{x}_t+(1 - \\alpha_t)\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0}{(1-\\bar{\\alpha}_t)}\\right]^2\\right)$$ which is clearly the pdf of a gaussian. Hence, $$\\boxed{q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0)=\\mathcal{N}\\left(\\mathbf{x}_{t-1}| \\frac{(1-\\bar{\\alpha}_{t-1})\\sqrt{\\alpha_t}\\mathbf{x}_t+(1 - \\alpha_t)\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0}{(1-\\bar{\\alpha}_t)},\\frac{(1 - \\alpha_t)(1 - \\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}\\mathbf{I}\\right)}$$ Re-parameterisation of Mean Our mean $\\mu_\\theta(\\mathbf{x}_t,t)$ is given by $$\\mu(\\mathbf{x}_t,t) = \\frac{(1-\\bar{\\alpha}_{t-1})\\sqrt{\\alpha_t}\\mathbf{x}_t+(1 - \\alpha_t)\\sqrt{\\bar{\\alpha}_{t-1}}\\mathbf{x}_0}{(1-\\bar{\\alpha}_t)}$$ We know $$\\mathbf{x}_t=\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_{0}+ \\sqrt{1-\\bar{\\alpha}_t}\\boldsymbol{\\epsilon}_t $$ Hence, we can write $\\mathbf{x}_0$ as $$\\mathbf{x}_0=\\frac{1}{\\sqrt{\\bar{\\alpha}_t}}\\left(\\mathbf{x}_t-\\sqrt{1-\\bar{\\alpha}_t}\\boldsymbol{\\epsilon}_t\\right)$$ Plugging the above into our mean $$\\begin{aligned} \\mu(\\mathbf{x}_t,t) =\u0026 \\frac{(1 - \\bar{\\alpha}_{t-1})\\sqrt{\\alpha_t}\\mathbf{x}_t + (1-\\alpha_t)\\sqrt{\\bar{\\alpha}_{t-1}}\\left( \\frac{\\mathbf{x}_t}{\\sqrt{\\bar{\\alpha}_t}} - \\frac{\\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon}_\\theta}{\\sqrt{\\bar{\\alpha}_t}} \\right)}{1 - \\bar{\\alpha}_t} \\\\ =\u0026\\frac{1}{\\sqrt{\\alpha}_t} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}}\\boldsymbol{\\epsilon}_t \\right) \\end{aligned} $$ Final Training Loss Recall that we need to learn a neural network to approximate the conditioned probability distributions in the reverse diffusion process,\n$$p_{\\theta}(\\mathbf{x}_{t-1}|\\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\mu_{\\theta}(\\mathbf{x}_t, t), \\Sigma_{\\theta}(\\mathbf{x}_t, t))$$ We would like to train $\\mu_{\\theta}$ to predict \\(\\mu(\\mathbf{x}_t,t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1-\\bar{\\alpha}_t}{\\sqrt{1-\\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_t \\right)\\). Because \\(\\mathbf{x}_t\\) is available as input at training time, we can re-parameterise the Gaussian noise term instead to make it predict \\(\\boldsymbol{\\epsilon}_t\\) from the input \\(\\mathbf{x}_t\\) at time step $t$ $$\\mu_{\\theta}(\\mathbf{x}_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1-\\bar{\\alpha}_t}{\\sqrt{1-\\bar{\\alpha}_t}} \\epsilon_{\\theta}(\\mathbf{x}_t, t) \\right)$$ Therefore $L_t$ is the KL-Divergence between \\(p_{\\theta}(\\mathbf{x}_{t-1}|\\mathbf{x}_t)\\) and \\(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0)\\). KL-Divergence between two normal distributions - \\(\\mathcal{N}(\\boldsymbol{\\mu}_1,\\boldsymbol{\\Sigma}_1)\\) and \\(\\mathcal{N}(\\boldsymbol{\\mu}_2,\\boldsymbol{\\Sigma}_2)\\) can be written as $$\\frac{1}{2} \\left[ \\log\\frac{|\\boldsymbol{\\Sigma}_2|}{|\\boldsymbol{\\Sigma}_1|}-n+\\text{tr}(\\boldsymbol{\\Sigma}_2^{-1}\\boldsymbol{\\Sigma}_1) + (\\boldsymbol{\\mu}_2-\\boldsymbol{\\mu}_1)^{\\intercal} \\boldsymbol{\\Sigma}^{-1}_2(\\boldsymbol{\\mu}_2-\\boldsymbol{\\mu}_1) \\right]$$ Therefore, $$\\log\\frac{|\\boldsymbol{\\Sigma}_2|}{|\\boldsymbol{\\Sigma}_1|}=0$$ and $$\\text{tr}(\\boldsymbol{\\Sigma}_2^{-1}\\boldsymbol{\\Sigma}_1)=\\mathbf{I}$$ Since $$\\Sigma_{\\theta}(\\mathbf{x}_t, t)=\\Sigma(\\mathbf{x}_t, t)=\\frac{(1 - \\alpha_t)(1 - \\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}$$ for which $\\mathbf{I}$ and $n$ can be ignore in our final loss term as they aren’t parameterised by $\\theta$. We have $$\\frac{1}{2} \\left[ (\\boldsymbol{\\mu}_2-\\boldsymbol{\\mu}_1)^{\\intercal} \\boldsymbol{\\Sigma}^{-1}_2(\\boldsymbol{\\mu}_2-\\boldsymbol{\\mu}_1) \\right]$$ Let’s rewrite the above with our terms we derived in the earlier sections $$\\begin{aligned} \u0026\\frac{1}{2} \\left[ (\\boldsymbol{\\mu}(\\mathbf{x}_t,t)-\\mu_\\theta(\\mathbf{x}_t,t))^{\\intercal} \\boldsymbol{\\Sigma}^{-1}_\\theta(\\boldsymbol{\\mu}(\\mathbf{x}_t,t)-\\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t,t)) \\right]\\\\ =\u0026\\left[ \\frac{1}{2\\|\\boldsymbol{\\Sigma}_\\theta\\|_2^2} \\left\\| \\mu_{\\theta}(\\mathbf{x}_t, \\mathbf{x}_0) - \\mu_{\\theta}(\\mathbf{x}_t, t) \\right\\|_2^2 \\right]\\\\ \\end{aligned}$$ Plugging in $\\mu_{\\theta}(\\mathbf{x}_t, t)$ and $\\mu(\\mathbf{x}_t,t)$, we get $$\\frac{(1 - \\alpha_t)^2}{2\\alpha_t (1 - \\bar{\\alpha}_t)\\|\\boldsymbol{\\Sigma}_\\theta\\|_2^2} \\left\\| \\boldsymbol{\\epsilon}_t - \\boldsymbol{\\epsilon}_{\\theta} \\left( \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon}_t, t \\right) \\right\\|_2^2 $$ Simplification The authors of the original DDPM suggested to use only the norm term and ignore the weighing term as empirically it performed better. So we get, $$ \\boxed{L_t^{\\text{simple}} = \\mathbb{E}_{t\\sim\\mathcal{U}[1,T], \\mathbf{x}_0, \\boldsymbol{\\epsilon}} \\left[ \\left\\| \\boldsymbol{\\epsilon}_t - \\boldsymbol{\\epsilon}_{\\theta}\\left( \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon}_t, t \\right) \\right\\|_2^2 \\right]} $$ which is our final objective function.\nAlgorithm Algorithm 1: Training repeat\n$\\mathbf{x}_0 \\sim q(\\mathbf{x}_0)$ $t \\sim \\text{Uniform}({1, \\ldots, T})$ $\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, \\mathbf{I})$ Take gradient descent step on $\\nabla_{\\theta} |\\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_{\\theta}(\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1-\\bar{\\alpha}_t}\\boldsymbol{\\epsilon}, t)|^2$ until converged\nAlgorithm 2: Sampling $\\mathbf{x}_T \\sim \\mathcal{N}(0, \\mathbf{I})$ for $t = T, \\ldots, 1$ do $\\mathbf{z} \\sim \\mathcal{N}(0, \\mathbf{I})$ if $t \u003e 1$, else $\\mathbf{z} = \\mathbf{0}$ \\(\\mathbf{x}_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left(\\mathbf{x}_t-\\frac{1-\\alpha_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\boldsymbol{\\epsilon}_{\\theta}(\\mathbf{x}_t, t)\\right) + \\sigma_t \\mathbf{z}\\) end for return $\\mathbf{x}_0$ Implementation For the model, a U-Net was used where $t$ was fed in as a positional embedding in its intermediate layers. A implementation of DDPM can be found here.\nReferences (1) Jonathan Ho et al. “Denoising diffusion probabilistic models.” arxiv Preprint arxiv:2006.11239 (2020).\n(2) Lilian Weng. (Jul 2021). “What are diffusion models? Lil’Log”.\n(3) Tushar Kumar. (Nov 2023). “Denoising Diffusion Probabilistic Models | DDPM Explained”.\n",
  "wordCount" : "1927",
  "inLanguage": "en",
  "datePublished": "2024-04-24T18:47:49+05:30",
  "dateModified": "2024-04-24T18:47:49+05:30",
  "author":[{
    "@type": "Person",
    "name": "Sasmit Datta"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://example.org/posts/ddpm/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Sasmit's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://example.org/favicon.ico"
    }
  }
}
</script>
    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '\\[', right: '\\]', display: true},   
        {left: '$$', right: '$$', display: true},     
        {left: '\\(', right: '\\)', display: false},  
        {left: '$', right: '$', display: false}
      ],
      throwOnError : false
    });
  });
</script>
    
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://example.org/" accesskey="h" title="Sasmit&#39;s Blog (Alt + H)">Sasmit&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      The Math of DDPMs
    </h1>
    <div class="post-meta"><span title='2024-04-24 18:47:49 +0530 IST'>April 24, 2024</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;Sasmit Datta

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#ddpms" aria-label="DDPMs">DDPMs</a></li>
                <li>
                    <a href="#forward-diffusion-process" aria-label="Forward Diffusion Process">Forward Diffusion Process</a><ul>
                        
                <li>
                    <a href="#result-1" aria-label="Result 1">Result 1</a></li>
                <li>
                    <a href="#one-shot-forward-diffusion" aria-label="One-Shot Forward Diffusion">One-Shot Forward Diffusion</a></li></ul>
                </li>
                <li>
                    <a href="#reverse-diffusion-process" aria-label="Reverse Diffusion Process">Reverse Diffusion Process</a><ul>
                        
                <li>
                    <a href="#simplifying-the-likelihood" aria-label="Simplifying the Likelihood">Simplifying the Likelihood</a></li>
                <li>
                    <a href="#pdf-of-of-l_t" aria-label="PDF of of $L_t$">PDF of of $L_t$</a></li>
                <li>
                    <a href="#re-parameterisation-of-mean" aria-label="Re-parameterisation of Mean">Re-parameterisation of Mean</a></li></ul>
                </li>
                <li>
                    <a href="#final-training-loss" aria-label="Final Training Loss">Final Training Loss</a><ul>
                        
                <li>
                    <a href="#simplification" aria-label="Simplification">Simplification</a></li></ul>
                </li>
                <li>
                    <a href="#algorithm" aria-label="Algorithm">Algorithm</a><ul>
                        
                <li>
                    <a href="#algorithm-1-training" aria-label="Algorithm 1: Training">Algorithm 1: Training</a></li>
                <li>
                    <a href="#algorithm-2-sampling" aria-label="Algorithm 2: Sampling">Algorithm 2: Sampling</a></li></ul>
                </li>
                <li>
                    <a href="#implementation" aria-label="Implementation">Implementation</a></li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h1>
<p>This blog post dives deep into the mathematics behind Denoising Diffusion Probabilistic Models, breaking down the objective function that make DDPMs work. I tried to &ldquo;hand-wave&rdquo; as little math as possible in this post and tried my best to cover all the steps in this derivation.</p>
<h1 id="ddpms">DDPMs<a hidden class="anchor" aria-hidden="true" href="#ddpms">#</a></h1>
<p>Diffusion models are inspired by non-equilibrium thermodynamics. They define a Markov chain to slowly add random noise to data and learn to reverse the diffusion to get the original data sample back from the noise. The idea is to generate images from noise by iteratively removing &ldquo;noise&rdquo; from it.</p>
<h1 id="forward-diffusion-process">Forward Diffusion Process<a hidden class="anchor" aria-hidden="true" href="#forward-diffusion-process">#</a></h1>
<p>Given a sample datapoint $\mathbf{x}_0\sim q(\mathbf{x})$, forward diffusion process is addition of small amounts of gaussian noise to sample in $T$ time-steps, producing a sequence of noisy samples $\mathbf{x}_1,&hellip;\mathbf{x}_T$ controlled a by a variance schedule \(\{\beta_t\in(0,1)\}_{t=1}^{T}\).<br>
</p>
$$\boxed{q(\mathbf{x}_t|\mathbf{x}_{t-1})=\mathcal{N}(\mathbf{x}_t|\sqrt{1-\beta_t}\mathbf{x}_{t-1},\beta_t\mathbf{I})} \tag{1}$$
$$q(\mathbf{x}_{1:T}|\mathbf{x}_0)=\prod_{t=1}^{T}q(\mathbf{x}_t|\mathbf{x}_{t-1}) \tag{2}$$
<p>
The data sample loses its features and becomes more noisy as it propagates through the forward process.</p>
<h2 id="result-1">Result 1<a hidden class="anchor" aria-hidden="true" href="#result-1">#</a></h2>
<p><em>As $T\rightarrow \infty$, $\mathbf{x}_T$ is equivalent to an isotropic Gaussian</em>.</p>
<p><em>Proof.</em>
Let us assume a constant schedule:
</p>
$$\beta_t=\beta$$
<p>
We know,
</p>
$$q(\mathbf{x}_T|\mathbf{x}_{T-1})=\mathcal{N}(\mathbf{x}_T|\sqrt{1-\beta}\mathbf{x}_{T-1},\beta\mathbf{I})$$
<p>
According to the re-parametrisation trick,
</p>
$$\mathbf{x}_T=\sqrt{1-\beta}\mathbf{x}_{T-1}+\sqrt{\beta}\mathcal{N}(\mathbf{0},\mathbf{I})$$
<p>
Therefore expanding on this,
</p>
$$
\begin{aligned}
&\mathbf{x}_T=\sqrt{1-\beta}\mathbf{x}_{T-1}+\sqrt{\beta}\mathcal{N}(\mathbf{0},\mathbf{I})\\
&\mathbf{x}_T= \sqrt{1-\beta}(\sqrt{1-\beta}\mathbf{x}_{T-2}+\sqrt{\beta}\mathcal{N}(\mathbf{0},\mathbf{I})) + \sqrt{\beta}\mathcal{N}(\mathbf{0},\mathbf{I})\\
&\mathbf{x}_T=\sqrt{1-\beta}^2\mathbf{x}_{T-2}+\sqrt{1-\beta}\sqrt{\beta}\mathcal{N}(\mathbf{0},\mathbf{I}) +\sqrt{\beta}\mathcal{N}(\mathbf{0},\mathbf{I})\\
&\mathbf{x}_T=\sqrt{1-\beta}^2(\sqrt{1-\beta}\mathbf{x}_{T-3}+\sqrt{\beta}\mathcal{N}(\mathbf{0},\mathbf{I}))+\sqrt{1-\beta}\sqrt{\beta}\mathcal{N}(\mathbf{0},\mathbf{I}) +\sqrt{\beta}\mathcal{N}(\mathbf{0},\mathbf{I})\\
&\mathbf{x}_T=\sqrt{1-\beta}^T\mathbf{x}_{0}+\sqrt{1-\beta}^{T-1}\sqrt{\beta}\mathcal{N}(\mathbf{0},\mathbf{I}) +...+\sqrt{1-\beta}\sqrt{\beta}+\sqrt{\beta}\mathcal{N}(\mathbf{0},\mathbf{I})\\
&\mathbf{x}_T=\sqrt{1-\beta}^T\mathbf{x}_{0}+\mathcal{N}(\mathbf{0},\mathbf{I})(\sqrt{1-\beta}^{T-1}\sqrt{\beta} +...+\sqrt{1-\beta}\sqrt{\beta}+\sqrt{\beta})\\
\end{aligned}$$
<p>
The second term is GP sum with a common ratio $\sqrt{1-\beta}$. Therefore,
</p>
$$\mathbf{x}_T=\sqrt{1-\beta}^T\mathbf{x}_{0}+\sqrt\beta\frac{1-\sqrt{1-\beta}^{T-1}}{1-\sqrt{1-\beta}}\mathcal{N}(\mathbf{0},\mathbf{I})$$
<p>
Since, $\beta&laquo;1$ and $T\rightarrow\infty$,
</p>
$$\mathbf{x}_T\approx\mathcal{N}(\mathbf{0},\mathbf{I})$$
<h2 id="one-shot-forward-diffusion">One-Shot Forward Diffusion<a hidden class="anchor" aria-hidden="true" href="#one-shot-forward-diffusion">#</a></h2>
<p>Instead of performing the forward diffusion process $T$ times, we can formulate an equation that can compute it at a single go.</p>
<p>Let us assume,
</p>
$$\boxed{\alpha_t=1-\beta_t}\tag{3}$$
<p>
Therefore, we can write our forward process of $t$-th step as
</p>
$$\mathbf{x}_t=\sqrt{\alpha_t}\mathbf{x}_{t-1}+\sqrt{1-\alpha_t}\epsilon_t$$
<p>
where, $\epsilon_t\sim\mathcal{N}(\mathbf{0},\mathbf{I})$. Noise from all time-steps are samples from a normal distribution.</p>
<p>Expanding on this,
</p>
$$
\begin{aligned}
&\mathbf{x}_t=\sqrt{\alpha_t}\mathbf{x}_{t-1}+
\sqrt{1-\alpha_t}\epsilon_t \\
&\mathbf{x}_t=\sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}\mathbf{x}_{t-2}+
\sqrt{1-\alpha_{t-1}}\epsilon_{t-1})+
\sqrt{1-\alpha_t}\epsilon_t \\
&\mathbf{x}_t=\sqrt{\alpha_t}\sqrt{\alpha_{t-1}}\mathbf{x}_{t-2}+
\sqrt{\alpha_t}\sqrt{1-\alpha_{t-1}}\epsilon_{t-1}+
\sqrt{1-\alpha_t}\epsilon_t \\
\end{aligned}
$$
<p>
Now, we know that when
</p>
$$
\begin{aligned}
&X\sim N(\mu_{X},\sigma_{X}^{2})\\
&Y\sim N(\mu_{Y},\sigma_{Y}^{2})\\
&Z=X+Y\\
\end{aligned}
$$
<p>
Then,
</p>
$$Z\sim N(\mu_{X}+\mu_{Y},\sigma _{X}^{2}+\sigma_{Y}^{2})$$
<p>
So,
</p>
$$\sqrt{\alpha_t}\sqrt{1-\alpha_{t-1}}\epsilon_{t-1}+
\sqrt{1-\alpha_t}\epsilon_t=\sqrt{\alpha_t(1-\alpha_{t-1})+1-\alpha_t}\epsilon$$
<p>
And hence, coming back to our formulation
</p>
$$\begin{aligned}
&\mathbf{x}_t=\sqrt{\alpha_t}\sqrt{\alpha_{t-1}}\mathbf{x}_{t-2}+
\sqrt{\alpha_t-\alpha_t\alpha_{t-1}+1-\alpha_t}\epsilon \\
&\mathbf{x}_t=\sqrt{\alpha_t\alpha_{t-1}}\mathbf{x}_{t-2}+
\sqrt{1-\alpha_t\alpha_{t-1}}\epsilon \\
\end{aligned}
$$
<p>
If we keep iteratively doing this, we arrive at a formula,
</p>
$$
\mathbf{x}_t=\sqrt{\alpha_t\alpha_{t-1}...\alpha_2\alpha_1}\mathbf{x}_{0}+
\sqrt{1-\alpha_t\alpha_{t-1}...\alpha_2\alpha_1}\epsilon \\
$$
<p>
Let,
</p>
$$\boxed{\bar{\alpha}_t=\prod_{i=1}^{t}\alpha_i}\tag{4}$$
<p>
Finally,
</p>
$$\boxed{
\mathbf{x}_t=\sqrt{\bar{\alpha}_t}\mathbf{x}_{0}+
\sqrt{1-\bar{\alpha}_t}\epsilon} \tag{5}\\
$$
<h1 id="reverse-diffusion-process">Reverse Diffusion Process<a hidden class="anchor" aria-hidden="true" href="#reverse-diffusion-process">#</a></h1>
<p>Through the reverse diffusion process, we want to sample from \(q(\mathbf{x}_{t-1}|\mathbf{x}_{t})\) to able to recreate the original image from a Gaussian noise $\mathbf{x}_T\sim\mathcal{N}(\mathbf{0},\mathbf{I})$.</p>
<p>Unfortunately, we cannot compute \(q(\mathbf{x}_{t-1}|\mathbf{x}_{t})\) as it requires the entire data distribution to compute.</p>
<p>So we learn a model $p_\theta$ to approximate these conditional probabilities.
</p>
$$p_\theta(\mathbf{x}_{0:T})=p_\theta(\mathbf{x}_T)\prod_{t=1}^{T}p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_{t}) \tag{6}$$
<p>
We model our approximate reverse diffusion process parametrising the mean and variance of the noise to be estimated. We assume it is a <strong>normal distribution</strong>.
</p>
$$p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_{t})=\mathcal{N}(\mathbf{x}_{t-1}|\boldsymbol{\mu}_\theta(\mathbf{x}_t,t),\boldsymbol{\Sigma}_\theta(\mathbf{x}_t,t))$$
<p>
This kind of setup is very similar to a VAE where we want to maximise
</p>
$$\log p_\theta(\mathbf{x}_0)$$
<p>
Hence,
</p>
$$\begin{aligned}
\log p_\theta(\mathbf{x}_0) &= 
\log p_\theta(\mathbf{x}_0)\cdot 
\int q(\mathbf{x}_{1:T}|\mathbf{x}_0) d\mathbf{x}_{1:T}\\
&= \int \log p_\theta(\mathbf{x}_0) q(\mathbf{x}_{1:T}|\mathbf{x}_0) d\mathbf{x}_{1:T}\\
&=\mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}
\left[ \log p_\theta(\mathbf{x}_0)  \right]
\end{aligned}$$
<p>
Now the term \(\mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}[ \log p_\theta(\mathbf{x}_0)]\) can be further be broken down using Bayes rule. So from $(2)$ and $(6)$
</p>
$$\mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}
\left[ \log \frac{p_\theta(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}  \right] \tag{7}
$$
<p>
Eq $(7)$ is for a single point in our dataset. We want to find the expectation of the likelihood over the entire distribution,
</p>
$$\mathbb{E}_{q(\mathbf{x}_0)}\left[ \mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}
\left[ \log \frac{p_\theta(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}  \right] \right]
$$
<p>
which can be written as
</p>
$$\int\int\log \frac{p_\theta(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}q(\mathbf{x}_{1:T}|\mathbf{x}_0) d\mathbf{x}_{1:T}\cdot q(\mathbf{x}_0)d\mathbf{x}_0$$
<p>
Since \(q(\mathbf{x}_{0:T})=q(\mathbf{x}_0)q(\mathbf{x}_{1:T}|\mathbf{x}_0)\), our final log-likelihood can be written as
</p>
$$
\mathbb{E}_{q(\mathbf{x}_{0:T})}
\left[ \log \frac{p_\theta(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}  \right] \tag{8}
$$
<p>
Maximising eq $(8)$ is equivalent to minimising:
</p>
$$
\mathbb{E}_{q(\mathbf{x}_{0:T})}
\left[ \log \frac{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})}  \right] = \mathcal{L}_{\text{VLB}}\tag{8}
$$
<h2 id="simplifying-the-likelihood">Simplifying the Likelihood<a hidden class="anchor" aria-hidden="true" href="#simplifying-the-likelihood">#</a></h2>
<p>So taking the \(\mathcal{L}_{\text{VLB}}\),
</p>
$$
\begin{align}
&= \mathbb{E}_{q} \left[ \log \frac{q(\mathbf{x}_T | \mathbf{x}_0)}{p_\theta(\mathbf{x}_T)} + \sum_{t=2}^{T} \log \frac{q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)} - \log p_\theta(\mathbf{x}_0 | \mathbf{x}_1) \right] \\
&= \mathbb{E}_{q} \left[ D_{KL}(q(\mathbf{x}_T | \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_T))  + \sum_{t=2}^{T}  D_{KL}(q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)) - \log p_\theta(\mathbf{x}_0 | \mathbf{x}_1) \right]
\end{align}
$$
$$\begin{align}
\mathcal{L}_{\text{VLB}} &= \mathbb{E}_{q(\mathbf{x}_{0:T})} \left[ \log \frac{q(\mathbf{x}_{1:T} | \mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \right] \\
\end{align}$$
<p>
So expanding using $(6)$ an $(2)$ and taking \(q=q(\mathbf{x}_{0:T}) \)
</p>
$$\begin{aligned}
&\mathbb{E}_{q} \left[ \log \frac{\prod_{t=1}^{T} q(\mathbf{x}_t | \mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_T) \prod_{t=1}^{T} p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)} \right]\\
=& \mathbb{E}_{q} \left[ - \log p_\theta(\mathbf{x}_T) + \sum_{t=1}^{T} \log \frac{q(\mathbf{x}_t | \mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)} \right] \\
\end{aligned}$$
<p>
Now separating the summation (starting it from $t=2$ and stripping out $t=1$)
</p>
$$\begin{aligned}
\mathbb{E}_{q} \left[ - \log p_\theta(\mathbf{x}_T) + \sum_{t=2}^{T} \log \frac{q(\mathbf{x}_{t} | \mathbf{x}_{t-1}, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)} + \log \frac{q(\mathbf{x}_1 | \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 | \mathbf{x}_1)} \right] \\
\end{aligned}$$
<p>
Note that \(q(\mathbf{x}_{t} | \mathbf{x}_{t-1})=q(\mathbf{x}_{t} | \mathbf{x}_{t-1},\mathbf{x}_0)\) as $q$ is a Markov chain. Conditioning it on \(\mathbf{x}_0\) won&rsquo;t change anything. Now focusing on the summation, using Bayes rule, we get
</p>
$$
\begin{aligned}
&\mathbb{E}_{q} \left[ - \log p_\theta(\mathbf{x}_T) + \sum_{t=2}^{T} \log \left( \frac{q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)} \cdot \frac{q(\mathbf{x}_t | \mathbf{x}_0)}{q(\mathbf{x}_{t-1} | \mathbf{x}_0)} \right) + \log \frac{q(\mathbf{x}_1 | \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 | \mathbf{x}_1)} \right]\\
=&\mathbb{E}_{q} \left[ - \log p_\theta(\mathbf{x}_T) + \sum_{t=2}^{T} \log \frac{q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)} + \sum_{t=2}^{T} \log \frac{q(\mathbf{x}_t | \mathbf{x}_0)}{q(\mathbf{x}_{t-1} | \mathbf{x}_0)} + \log \frac{q(\mathbf{x}_1 | \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 | \mathbf{x}_1)} \right] \\
\end{aligned}$$
<p>
Now observing the term
</p>
$$\sum_{t=2}^{T} \log \frac{q(\mathbf{x}_t | \mathbf{x}_0)}{q(\mathbf{x}_{t-1} | \mathbf{x}_0)}=\frac{q(\mathbf{x}_2| \mathbf{x}_0)...q(\mathbf{x}_{T-1} | \mathbf{x}_0)q(\mathbf{x}_T | \mathbf{x}_0)}{q(\mathbf{x}_1 | \mathbf{x}_0)q(\mathbf{x}_2 | \mathbf{x}_0)...q(\mathbf{x}_{T-1} | \mathbf{x}_0)}$$
<p>
There&rsquo;s clear recursive cancellation that takes place leaving us with our final term
</p>
$$\log\frac{q(\mathbf{x}_T | \mathbf{x}_0)}{q(\mathbf{x}_1 | \mathbf{x}_0)}$$
<p>
Therefore plugging it back into our $\mathcal{L}_{\text{VLB}}$
</p>
$$
\begin{align*}
&\mathbb{E}_q \left[ - \log p_\theta(\mathbf{x}_T) + \sum_{t=2}^{T} \log \frac{q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)} + \log \frac{q(\mathbf{x}_T|\mathbf{x}_0)}{q(\mathbf{x}_1|\mathbf{x}_0)} + \log \frac{q(\mathbf{x}_1|\mathbf{x}_0)}{p_\theta(\mathbf{x}_0|\mathbf{x}_1)} \right] \\
=&\mathbb{E}_q \left[ \log \frac{q(\mathbf{x}_T|\mathbf{x}_0)}{p_\theta(\mathbf{x}_T)} + \sum_{t=2}^{T} \log \frac{q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)} - \log p_\theta(\mathbf{x}_0|\mathbf{x}_1) \right] \\
=&\mathbb{E}_q \left[ D_{KL}(q(\mathbf{x}_T|\mathbf{x}_0) \| p_\theta(\mathbf{x}_T)) + \sum_{t=2}^{T} D_{KL}(q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) \| p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)) - \log p_\theta(\mathbf{x}_0|\mathbf{x}_1) \right]
\end{align*}
$$
<p>
Let us divide the final term into smaller chunks</p>
<ul>
<li>\(L_T=D_{KL}(q(\mathbf{x}_T | \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_T))\)</li>
<li>\(L_{t}=D_{KL}(q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t))\) where \(2\leq t \leq T-1\)</li>
<li>\(L_0=\log p_\theta(\mathbf{x}_0 | \mathbf{x}_1)\)</li>
</ul>
<h2 id="pdf-of-of-l_t">PDF of of $L_t$<a hidden class="anchor" aria-hidden="true" href="#pdf-of-of-l_t">#</a></h2>
<p>We have the general term for a reverse diffusion process:
</p>
$$q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0)$$
<p>
This is a tractable expression as we have the reverse process being conditioned on $\mathbf{x}_0$ - a single datapoint and not the entire data distribution.</p>
<p>Using Bayes theorem, we can write this as:
</p>
$$q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0)=\frac{q(\mathbf{x}_{t}|\mathbf{x}_{t-1},\mathbf{x}_{0})q(\mathbf{x}_{t-1}|\mathbf{x}_{0})}{q(\mathbf{x}_{t}|\mathbf{x}_{0})}$$
<p>
For our forward process, \(q(\mathbf{x}_{t}|\mathbf{x}_{t-1},\mathbf{x}_{0})\) is a Markov chain, hence, \(q(\mathbf{x}_{t}|\mathbf{x}_{t-1},\mathbf{x}_{0})=q(\mathbf{x}_{t}|\mathbf{x}_{t-1})\). So our given pdfs can easily be written expressions we already have. \(q(\mathbf{x}_{t}|\mathbf{x}_{0})\) and \((\mathbf{x}_{t-1}|\mathbf{x}_{0})\)  is equation $(5)$.
</p>
$$q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0)=\frac{\mathcal{N}(\mathbf{x}_{t}|\sqrt{\alpha_t}\mathbf{x}_{t-1},(1-\alpha_t)\mathbf{I}) \mathcal{N}(\mathbf{x}_{t-1}|\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_{0},(1-\bar{\alpha}_{t-1})\mathbf{I})}{\mathcal{N}(\mathbf{x}_{t}|\sqrt{\bar{\alpha}_{t}}\mathbf{x}_{0},(1-\bar{\alpha}_{t})\mathbf{I})}$$
<p>
<strong>Our goal is to find a gaussian pdf</strong> with mean a function of \(\mathbf{x}_t\) and \( \mathbf{x}_0 \) (during training we&rsquo;ll have access to both values). So expanding the above and take only the exponential terms, we get
</p>
$$\exp\left(-\frac{1}{2}\left[\frac{(\mathbf{x}_t - \sqrt{\alpha_t}\mathbf{x}_{t-1})^2}{1-\alpha_t} + \frac{(\mathbf{x}_{t-1} - \sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0)^2}{1-\bar{\alpha}_{t-1}} - \frac{(\mathbf{x}_t - \sqrt{\bar{\alpha}_t}\mathbf{x}_0)^2}{1-\bar{\alpha}_t}\right]\right)
$$
<p>
Our first strategy will be to take all the $\mathbf{x}_{t-1}$ terms and group them together. So, we expand the above terms:</p>
<ol>
<li>\(\frac{(\mathbf{x}_t - \sqrt{\alpha_t}\mathbf{x}_{t-1})^2}{1-\alpha_t} = \frac{\mathbf{x}_t^2 - 2\mathbf{x}_t\sqrt{\alpha_t}\mathbf{x}_{t-1} + \alpha_t \mathbf{x}_{t-1}^2}{1-\alpha_t}\)</li>
<li>\(\frac{(\mathbf{x}_{t-1} - \sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0)^2}{1-\bar{\alpha}_{t-1}} = \frac{\mathbf{x}_{t-1}^2 - 2\mathbf{x}_{t-1}\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0 + \bar{\alpha}_{t-1} \mathbf{x}_0^2}{1-\bar{\alpha}_{t-1}}\)</li>
<li>\(\frac{(\mathbf{x}_t - \sqrt{\bar{\alpha}_t}\mathbf{x}_0)^2}{1-\bar{\alpha}_t} = \frac{\mathbf{x}_t^2 - 2\mathbf{x}_t\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \bar{\alpha}_t \mathbf{x}_0^2}{1-\bar{\alpha}_t}\)</li>
</ol>
<p>Now we separate the the \(\mathbf{x}_{t-1}\) terms and the rest. The \( \mathbf{x}_{t-1}\) terms in the exponential are
</p>
$$\begin{aligned}
&\mathbf{x}_{t-1}^2 \left( \frac{1-\bar{\alpha}_t}{(1 - \alpha_t)(1 - \bar{\alpha}_{t-1})} \right) - 2\mathbf{x}_{t-1} \left( \frac{\sqrt{\alpha_t}\mathbf{x}_t}{1 - \alpha_t} + \frac{\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0}{1 - \bar{\alpha}_{t-1}} \right)\\
=&\mathbf{x}_{t-1}^2 \left( \frac{1-\bar{\alpha}_t}{(1 - \alpha_t)(1 - \bar{\alpha}_{t-1})} \right) - 2\mathbf{x}_{t-1} \left( \frac{(1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}\mathbf{x}_t+(1 - \alpha_t)\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0}{(1 - \bar{\alpha}_{t-1})(1 - \alpha_t)}\right)\\
=& f(\mathbf{x}_{t-1})
\end{aligned}
$$
<p>
The rest are
</p>
$$\begin{aligned}
&\frac{\mathbf{x}_t^2}{1 - \alpha_t} + \frac{\bar{\alpha}_{t-1} \mathbf{x}_0^2}{1 - \bar{\alpha}_{t-1}} - \frac{\mathbf{x}_t^2}{1 - \bar{\alpha}_t} - \frac{\bar{\alpha}_t \mathbf{x}_0^2}{1 - \bar{\alpha}_t} + \frac{2\sqrt{\bar{\alpha}_t}\mathbf{x}_0\mathbf{x}_t}{1 - \bar{\alpha}_t}\\
=& \frac{1-\bar{\alpha_t}-1+\alpha_t}{(1-\bar{\alpha_t})(1-\alpha_t)}\mathbf{x}_t^2 + \frac{\bar{\alpha}_{t-1}-\bar{\alpha}_{t-1}\bar{\alpha}_{t}-\bar{\alpha}_{t}+\bar{\alpha}_{t-1}\bar{\alpha}_{t}}{(1-\bar{\alpha}_{t-1})(1-\bar{\alpha}_{t})}\mathbf{x}_0^2 + \frac{2\sqrt{\bar{\alpha}_t}\mathbf{x}_0\mathbf{x}_t}{1 - \bar{\alpha}_t}\\
=& \frac{\alpha_t-\bar{\alpha_t}}{(1-\bar{\alpha_t})(1-\alpha_t)}\mathbf{x}_t^2 + \frac{\bar{\alpha}_{t-1}-\bar{\alpha}_{t}}{(1-\bar{\alpha}_{t-1})(1-\bar{\alpha}_{t})}\mathbf{x}_0^2+\frac{2\sqrt{\bar{\alpha}_t}\mathbf{x}_0\mathbf{x}_t}{1 - \bar{\alpha}_t}\\
=&\frac{\alpha_t(1-\bar{\alpha}_{t-1})}{(1-\bar{\alpha_t})(1-\alpha_t)}\mathbf{x}_t^2 + \frac{\bar{\alpha}_{t-1}(1-\alpha_t)}{(1-\bar{\alpha}_{t-1})(1-\bar{\alpha}_{t})}\mathbf{x}_0^2+\frac{2\sqrt{\bar{\alpha}_t}\mathbf{x}_0\mathbf{x}_t}{1 - \bar{\alpha}_t}\\
\end{aligned}$$
<p>
The above is a squared sum. Hence, it can be written as
</p>
$$\begin{aligned}
&\frac{1}{1-\bar{\alpha}_t}\left(\sqrt{\frac{\alpha_t(1-\bar{\alpha}_{t-1})}{1-\alpha_t}}\mathbf{x}_t +  \sqrt{\frac{\bar{\alpha}_{t-1}(1-\alpha_t)}{1-\bar{\alpha}_{t-1}}}\mathbf{x}_0 \right)^2\\
=& \frac{1}{(1-\bar{\alpha}_t)(1 - \bar{\alpha}_{t-1})(1 - \alpha_t)}\left((1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}\mathbf{x}_t+(1 - \alpha_t)\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0 \right)^2\\
=&f(\mathbf{x}_{t},\mathbf{x}_0)
\end{aligned}$$
<p>
We want our \(\mathbf{x}_{t-1}^2\) to be separate as its the random variable we want to sample. So we common out \(\frac{1-\bar{\alpha}_t}{(1 - \alpha_t)(1 - \bar{\alpha}_{t-1})}\) from both \(f(\mathbf{x}_{t-1})\) and \(f(\mathbf{x}_{t},\mathbf{x}_0)\). Therefore doing so from \(f(\mathbf{x}_{t-1})\) will yield
</p>
$$\begin{aligned}
&\mathbf{x}_{t-1}^2 - 
2\mathbf{x}_{t-1} \left( \frac{(1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}\mathbf{x}_t+(1 - \alpha_t)\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0}{1-\bar{\alpha}_t}\right)\\
=&C(\mathbf{x}_{t-1})
\end{aligned}$$
<p>
and from \(f(\mathbf{x}_{t},\mathbf{x}_0)\) will yield
</p>
$$\begin{aligned}
&\frac{1}{(1-\bar{\alpha}_t)^2}\left((1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}\mathbf{x}_t+(1 - \alpha_t)\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0 \right)^2\\
=&\left(\frac{(1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}\mathbf{x}_t+(1 - \alpha_t)\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0}{(1-\bar{\alpha}_t)} \right)^2 \\
=& C(\mathbf{x}_t,\mathbf{x}_0)
\end{aligned}$$
<p>
Note: the above two terms <strong>aren&rsquo;t</strong> \(f(\mathbf{x}_{t-1})\) and \(f(\mathbf{x}_{t},\mathbf{x}_0)\). Zooming out for a moment to our original term in the exponential,
</p>
$$\begin{aligned}
&\exp\left(-\frac{1}{2}\left[\frac{(\mathbf{x}_t - \sqrt{\alpha_t}\mathbf{x}_{t-1})^2}{1-\alpha_t} + \frac{(\mathbf{x}_{t-1} - \sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0)^2}{1-\bar{\alpha}_{t-1}} - \frac{(\mathbf{x}_t - \sqrt{\bar{\alpha}_t}\mathbf{x}_0)^2}{1-\bar{\alpha}_t}\right]\right)\\
=&\exp\left(-\frac{1}{2}\left[f(\mathbf{x}_{t-1})+f(\mathbf{x}_{t},\mathbf{x}_0)\right]\right) \\
=& \exp-\frac{1}{2}\left(\frac{1}{\frac{(1 - \alpha_t)(1 - \bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}}\left[C(\mathbf{x}_{t-1})+C(\mathbf{x}_{t},\mathbf{x}_0)\right]\right)
\end{aligned}$$
<p>
Clearly, \(C(\mathbf{x}_{t-1})+C(\mathbf{x}_{t},\mathbf{x}_0)\) is a squared sum. Hence, we can write the above exponential as
</p>
$$\exp-\frac{1}{2}\left(\frac{1}{\frac{(1 - \alpha_t)(1 - \bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}}\left[\mathbf{x}_{t-1}-\frac{(1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}\mathbf{x}_t+(1 - \alpha_t)\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0}{(1-\bar{\alpha}_t)}\right]^2\right)$$
<p>
Now if we evaluate the normalisation terms of our three pdfs:</p>
<ol>
<li>$\frac{1}{\sqrt{(1-\alpha_t)2\pi}}$</li>
<li>$\frac{1}{\sqrt{(1-\bar{\alpha}_{t-1})2\pi}}$</li>
<li>\(\frac{1}{\sqrt{(1-\bar{\alpha}_{t})2\pi}}\)</li>
</ol>
<p>and compute the final normalisation term we get,
</p>
$$\frac{1}{\sqrt{\frac{(1 - \alpha_t)(1 - \bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}2\pi}}$$
<p>
Our final formula for $q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0)$ is
</p>
$$\frac{1}{\sqrt{\frac{(1 - \alpha_t)(1 - \bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}2\pi}}\exp-\frac{1}{2}\left(\frac{1}{\frac{(1 - \alpha_t)(1 - \bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}}\left[\mathbf{x}_{t-1}-\frac{(1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}\mathbf{x}_t+(1 - \alpha_t)\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0}{(1-\bar{\alpha}_t)}\right]^2\right)$$
<p>
which is clearly the pdf of a gaussian. Hence,
</p>
$$\boxed{q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0)=\mathcal{N}\left(\mathbf{x}_{t-1}| \frac{(1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}\mathbf{x}_t+(1 - \alpha_t)\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0}{(1-\bar{\alpha}_t)},\frac{(1 - \alpha_t)(1 - \bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\mathbf{I}\right)}$$
<h2 id="re-parameterisation-of-mean">Re-parameterisation of Mean<a hidden class="anchor" aria-hidden="true" href="#re-parameterisation-of-mean">#</a></h2>
<p>Our mean $\mu_\theta(\mathbf{x}_t,t)$ is given by
</p>
$$\mu(\mathbf{x}_t,t) = \frac{(1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}\mathbf{x}_t+(1 - \alpha_t)\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0}{(1-\bar{\alpha}_t)}$$
<p>
We know
</p>
$$\mathbf{x}_t=\sqrt{\bar{\alpha}_t}\mathbf{x}_{0}+
\sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}_t $$
<p>
Hence, we can write $\mathbf{x}_0$ as
</p>
$$\mathbf{x}_0=\frac{1}{\sqrt{\bar{\alpha}_t}}\left(\mathbf{x}_t-\sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}_t\right)$$
<p>
Plugging the above into our mean
</p>
$$\begin{aligned}
\mu(\mathbf{x}_t,t) =& \frac{(1 - \bar{\alpha}_{t-1})\sqrt{\alpha_t}\mathbf{x}_t + (1-\alpha_t)\sqrt{\bar{\alpha}_{t-1}}\left( \frac{\mathbf{x}_t}{\sqrt{\bar{\alpha}_t}} - \frac{\sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_\theta}{\sqrt{\bar{\alpha}_t}} \right)}{1 - \bar{\alpha}_t} \\
=&\frac{1}{\sqrt{\alpha}_t} \left( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}}\boldsymbol{\epsilon}_t \right)
\end{aligned}
$$
<h1 id="final-training-loss">Final Training Loss<a hidden class="anchor" aria-hidden="true" href="#final-training-loss">#</a></h1>
<p>Recall that we need to learn a neural network to approximate the conditioned probability distributions in the reverse diffusion process,<br>
</p>
$$p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \mu_{\theta}(\mathbf{x}_t, t), \Sigma_{\theta}(\mathbf{x}_t, t))$$
<p>
We would like to train  $\mu_{\theta}$ to predict \(\mu(\mathbf{x}_t,t) = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{1-\bar{\alpha}_t}{\sqrt{1-\bar{\alpha}_t}} \boldsymbol{\epsilon}_t \right)\). Because \(\mathbf{x}_t\) is available as input at training time, we can re-parameterise the Gaussian noise term instead to make it predict \(\boldsymbol{\epsilon}_t\) from the input \(\mathbf{x}_t\) at time step $t$
</p>
$$\mu_{\theta}(\mathbf{x}_t, t) = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{1-\bar{\alpha}_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_{\theta}(\mathbf{x}_t, t) \right)$$
<p>
Therefore $L_t$ is the KL-Divergence between \(p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_t)\) and \(q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0)\). KL-Divergence between two normal distributions - \(\mathcal{N}(\boldsymbol{\mu}_1,\boldsymbol{\Sigma}_1)\) and \(\mathcal{N}(\boldsymbol{\mu}_2,\boldsymbol{\Sigma}_2)\) can be written as
</p>
$$\frac{1}{2}
\left[
\log\frac{|\boldsymbol{\Sigma}_2|}{|\boldsymbol{\Sigma}_1|}-n+\text{tr}(\boldsymbol{\Sigma}_2^{-1}\boldsymbol{\Sigma}_1) + 
(\boldsymbol{\mu}_2-\boldsymbol{\mu}_1)^{\intercal}  \boldsymbol{\Sigma}^{-1}_2(\boldsymbol{\mu}_2-\boldsymbol{\mu}_1)
\right]$$
<p>
Therefore,
</p>
$$\log\frac{|\boldsymbol{\Sigma}_2|}{|\boldsymbol{\Sigma}_1|}=0$$
<p>
and
</p>
$$\text{tr}(\boldsymbol{\Sigma}_2^{-1}\boldsymbol{\Sigma}_1)=\mathbf{I}$$
<p>
Since
</p>
$$\Sigma_{\theta}(\mathbf{x}_t, t)=\Sigma(\mathbf{x}_t, t)=\frac{(1 - \alpha_t)(1 - \bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}$$
<p>
for which $\mathbf{I}$ and $n$ can be ignore in our final loss term as they aren&rsquo;t parameterised by $\theta$. We have
</p>
$$\frac{1}{2}
\left[ 
(\boldsymbol{\mu}_2-\boldsymbol{\mu}_1)^{\intercal}  \boldsymbol{\Sigma}^{-1}_2(\boldsymbol{\mu}_2-\boldsymbol{\mu}_1)
\right]$$
<p>
Let&rsquo;s rewrite the above with our terms we derived in the earlier sections
</p>
$$\begin{aligned}
&\frac{1}{2}
\left[ 
(\boldsymbol{\mu}(\mathbf{x}_t,t)-\mu_\theta(\mathbf{x}_t,t))^{\intercal}  \boldsymbol{\Sigma}^{-1}_\theta(\boldsymbol{\mu}(\mathbf{x}_t,t)-\boldsymbol{\mu}_\theta(\mathbf{x}_t,t))
\right]\\
=&\left[ \frac{1}{2\|\boldsymbol{\Sigma}_\theta\|_2^2} \left\| \mu_{\theta}(\mathbf{x}_t, \mathbf{x}_0) - \mu_{\theta}(\mathbf{x}_t, t) \right\|_2^2 \right]\\
\end{aligned}$$
<p>
Plugging in $\mu_{\theta}(\mathbf{x}_t, t)$ and $\mu(\mathbf{x}_t,t)$, we get
</p>
$$\frac{(1 - \alpha_t)^2}{2\alpha_t (1 - \bar{\alpha}_t)\|\boldsymbol{\Sigma}_\theta\|_2^2} \left\| \boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_{\theta} \left( \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t, t \right) \right\|_2^2 
$$
<h2 id="simplification">Simplification<a hidden class="anchor" aria-hidden="true" href="#simplification">#</a></h2>
<p>The authors of the original DDPM suggested to use only the norm term and ignore the weighing term as empirically it performed better. So we get,
</p>
$$
\boxed{L_t^{\text{simple}} = \mathbb{E}_{t\sim\mathcal{U}[1,T], \mathbf{x}_0, \boldsymbol{\epsilon}} \left[ \left\| \boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_{\theta}\left( \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t, t \right) \right\|_2^2 \right]}
$$
<p>
which is our final objective function.</p>
<h1 id="algorithm">Algorithm<a hidden class="anchor" aria-hidden="true" href="#algorithm">#</a></h1>
<h2 id="algorithm-1-training">Algorithm 1: Training<a hidden class="anchor" aria-hidden="true" href="#algorithm-1-training">#</a></h2>
<p><strong>repeat</strong></p>
<ol>
<li>$\mathbf{x}_0 \sim q(\mathbf{x}_0)$</li>
<li>$t \sim \text{Uniform}({1, \ldots, T})$</li>
<li>$\boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})$</li>
<li>Take gradient descent step on $\nabla_{\theta} |\boldsymbol{\epsilon} - \boldsymbol{\epsilon}_{\theta}(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}, t)|^2$</li>
</ol>
<p><strong>until converged</strong></p>
<h2 id="algorithm-2-sampling">Algorithm 2: Sampling<a hidden class="anchor" aria-hidden="true" href="#algorithm-2-sampling">#</a></h2>
<ol>
<li>$\mathbf{x}_T \sim \mathcal{N}(0, \mathbf{I})$</li>
<li>for $t = T, \ldots, 1$ do
<ol>
<li>$\mathbf{z} \sim \mathcal{N}(0, \mathbf{I})$ if $t &gt; 1$, else $\mathbf{z} = \mathbf{0}$</li>
<li>\(\mathbf{x}_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left(\mathbf{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, t)\right) + \sigma_t \mathbf{z}\)</li>
</ol>
</li>
<li>end for</li>
<li>return $\mathbf{x}_0$</li>
</ol>
<h1 id="implementation">Implementation<a hidden class="anchor" aria-hidden="true" href="#implementation">#</a></h1>
<p>For the model, a U-Net was used where $t$ was fed in as a positional embedding in its intermediate layers. A implementation of DDPM can be found <a href="https://github.com/Sasopsy/Diffusion-Models">here</a>.</p>
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p>(1) Jonathan Ho et al. <a href="https://arxiv.org/abs/2006.11239">“Denoising diffusion probabilistic models.”</a> arxiv Preprint arxiv:2006.11239 (2020).</p>
<p>(2) Lilian Weng. (Jul 2021). <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">&ldquo;What are diffusion models? Lil’Log&rdquo;</a>.</p>
<p>(3) Tushar Kumar. (Nov 2023). <a href="https://www.youtube.com/watch?v=H45lF4sUgiE">&ldquo;Denoising Diffusion Probabilistic Models | DDPM Explained&rdquo;</a>.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The Math of DDPMs on x"
            href="https://x.com/intent/tweet/?text=The%20Math%20of%20DDPMs&amp;url=https%3a%2f%2fexample.org%2fposts%2fddpm%2f&amp;hashtags=">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The Math of DDPMs on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fexample.org%2fposts%2fddpm%2f&amp;title=The%20Math%20of%20DDPMs&amp;summary=The%20Math%20of%20DDPMs&amp;source=https%3a%2f%2fexample.org%2fposts%2fddpm%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The Math of DDPMs on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fexample.org%2fposts%2fddpm%2f&title=The%20Math%20of%20DDPMs">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The Math of DDPMs on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fexample.org%2fposts%2fddpm%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The Math of DDPMs on whatsapp"
            href="https://api.whatsapp.com/send?text=The%20Math%20of%20DDPMs%20-%20https%3a%2f%2fexample.org%2fposts%2fddpm%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The Math of DDPMs on telegram"
            href="https://telegram.me/share/url?text=The%20Math%20of%20DDPMs&amp;url=https%3a%2f%2fexample.org%2fposts%2fddpm%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The Math of DDPMs on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=The%20Math%20of%20DDPMs&u=https%3a%2f%2fexample.org%2fposts%2fddpm%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://example.org/">Sasmit&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>






