<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Generative Adversarial Networks | Sasmit&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="Introduction The main idea: To train generators using really good classifiers.
Intuitive Explanation Imagine a counterfeiter tasked with creating fake paintings and a detective tasked with discerning fake from real paintings. Both of them are thrown in a game where they have to out compete each other. Through this, both of them will get have to get better in the methods they use to win the game.
Mathematical Explanation There are two models: A generative model $G$ that tries to capture the data distribution and a discriminative model $D$ that estimates the probability of a particular sample came from the training data.">
<meta name="author" content="Sasmit Datta">
<link rel="canonical" href="https://example.org/posts/gans/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://example.org/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://example.org/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://example.org/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://example.org/apple-touch-icon.png">
<link rel="mask-icon" href="https://example.org/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://example.org/posts/gans/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Generative Adversarial Networks" />
<meta property="og:description" content="Introduction The main idea: To train generators using really good classifiers.
Intuitive Explanation Imagine a counterfeiter tasked with creating fake paintings and a detective tasked with discerning fake from real paintings. Both of them are thrown in a game where they have to out compete each other. Through this, both of them will get have to get better in the methods they use to win the game.
Mathematical Explanation There are two models: A generative model $G$ that tries to capture the data distribution and a discriminative model $D$ that estimates the probability of a particular sample came from the training data." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://example.org/posts/gans/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-04-12T02:49:45+05:30" />
<meta property="article:modified_time" content="2024-04-12T02:49:45+05:30" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Generative Adversarial Networks"/>
<meta name="twitter:description" content="Introduction The main idea: To train generators using really good classifiers.
Intuitive Explanation Imagine a counterfeiter tasked with creating fake paintings and a detective tasked with discerning fake from real paintings. Both of them are thrown in a game where they have to out compete each other. Through this, both of them will get have to get better in the methods they use to win the game.
Mathematical Explanation There are two models: A generative model $G$ that tries to capture the data distribution and a discriminative model $D$ that estimates the probability of a particular sample came from the training data."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://example.org/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Generative Adversarial Networks",
      "item": "https://example.org/posts/gans/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Generative Adversarial Networks",
  "name": "Generative Adversarial Networks",
  "description": "Introduction The main idea: To train generators using really good classifiers.\nIntuitive Explanation Imagine a counterfeiter tasked with creating fake paintings and a detective tasked with discerning fake from real paintings. Both of them are thrown in a game where they have to out compete each other. Through this, both of them will get have to get better in the methods they use to win the game.\nMathematical Explanation There are two models: A generative model $G$ that tries to capture the data distribution and a discriminative model $D$ that estimates the probability of a particular sample came from the training data.",
  "keywords": [
    
  ],
  "articleBody": "Introduction The main idea: To train generators using really good classifiers.\nIntuitive Explanation Imagine a counterfeiter tasked with creating fake paintings and a detective tasked with discerning fake from real paintings. Both of them are thrown in a game where they have to out compete each other. Through this, both of them will get have to get better in the methods they use to win the game.\nMathematical Explanation There are two models: A generative model $G$ that tries to capture the data distribution and a discriminative model $D$ that estimates the probability of a particular sample came from the training data. Both $G$ and $D$ are put in this minimax adversarial game with a value function $V(G,D)$.\nFramework Both $G$ and $D$ are neural networks.\nTo learn $p_g$ which is the distribution of the generator’s over data $\\mathbf{x}$, we define a prior distribution $p_{\\mathbf{z}}(\\mathbf{z})$ where the input noise variable is sampled from. This is then mapped to the data space as $G(\\mathbf{z};\\theta_{g})$ where $G$ is a neural network with parameters $\\theta_{g}$.\n$D(\\mathbf{x},\\theta_d)$ on the other hand just outputs a single scaler ranging between $0$ and $1$ which represents the probability that the given piece of data is from our data distribution $p_d$ rather than $p_g$.\nHere’s the framework for training both of these neural nets: $$\\min_{G}\\max_{D} V(G,D)= \\mathbb{E}_{\\mathbf{x}\\sim p_{data}}[\\log D(\\mathbf{x})]+ \\mathbb{E}_{\\mathbf{z}\\sim p_{z}(\\mathbf{z})}[\\log(1-D(G(\\mathbf{z})))]$$ One important observation can be made from this is that the generator doesn’t directly ’look’ at the data. It tries to learn the distribution of it from just the ‘feedback’ of the discriminator.\nWhy does this work? What does $D$ predict? $$D(\\mathbf{x};\\theta_d)=P(\\mathbf{x}\\textnormal{ is real})$$ So it’s goal is to maximise, $$\\log D(\\mathbf{x})$$ when the given sample is from the training set ($\\mathbf{x}$ is a real data point). Conversely, the generators role is to minimise this as it’s trying to fool the discriminator.\nSimilarly, the discriminator’s goal is to maximise the second term when the data is from the generator. $$\\log(1-D(G(\\mathbf{z})))$$ The term $1-D(G(\\mathbf{z}))$ represents how fake the data is. So when the data is from the generator, the discriminator would want to maximise the log-likelihood of this term. Conversely, the generator would want to minimise this.\nFor training the generator we use the term, $$-\\log(D(G(\\mathbf{z})))$$ is used instead of $\\log(1-D(G(\\mathbf{z})))$. The reason is covered in a later section.\nTraining For training the adversarial net, discriminator is not started out fully trained. If so was the case, it would be hard for the generator to catch up. Instead, they are trained simultaneously with one step for optimising the discriminator and then one step for the generator.\nAlgorithm for number of iterations do\nSample minibatch of $m$ noise samples $\\set{\\mathbf{z}^{(1)},\\mathbf{z}^{(2)},…,\\mathbf{z}^{(m)}}$ from noise prior $p_g(\\mathbf{z})$. Sample minibatch of $m$ data samples $\\set{\\mathbf{x}^{(1)},\\mathbf{x}^{(2)},…,\\mathbf{x}^{(m)}}$ from training set. Update the discriminator by descending its stochastic gradient: $$\\nabla_{\\theta_d}\\frac{1}{m}\\sum_{i=1}^{m}\\left[-\\log D(\\mathbf{x^{(i)}}) - \\log(1-D(G(\\mathbf{z^{(i)}})))\\right]$$ Sample minibatch of $m$ noise samples $\\set{\\mathbf{z}^{(1)},\\mathbf{z}^{(2)},…,\\mathbf{z}^{(m)}}$ from noise prior $p_g(\\mathbf{z})$. Update the generator by descending its stochastic gradient: $$\\nabla_{\\theta_g}\\frac{1}{m}\\sum_{i=1}^{m}\\left[\\log(1-D(G(\\mathbf{z^{(i)}})))\\right]$$ end for Better Loss for Generator In practice, the given algorithm may not provide sufficient gradient for the generator in the initial stages of training. Early in training, $D$ has an easier time in rejecting samples from the generator. Hence, $\\log(1-D(G(\\mathbf{z})))$ saturates because $D(G(\\mathbf{z})) \\approx 0$ causing the generator to receive weak gradient signals.\nGoing deeper into why, $$\\frac{d\\log(1-D(G(\\mathbf{z})))}{dD(G(\\mathbf{z}))}=-\\frac{1}{1-D(G(\\mathbf{z}))}\\approx-1 \\space\\space.$$ In the final layer of $D$, we apply sigmoid to get a probability score $$D(G(\\mathbf{z}))=\\sigma(\\hat{\\mathbf{y}}) \\space\\space,$$ where $\\hat{\\mathbf{y}}$ is the pre-activation prediction of our discriminator and $\\sigma(x)$ is the sigmoid activation function. Taking the derivative $$\\frac{dD(G(\\mathbf{z}))}{d\\hat{\\mathbf{y}}}=\\sigma(\\hat{\\mathbf{y}})(1-\\sigma(\\hat{\\mathbf{y}}))=D(G(\\mathbf{z}))\\left[1-D(G(\\mathbf{z}))\\right] \\space\\space .$$ Since, $D(G(\\mathbf{z})) \\approx 0$, $$\\frac{dD(G(\\mathbf{z}))}{d\\hat{\\mathbf{y}}}\\approx0 \\space\\space.$$ This is a very weak gradient which can stunt training for our generator.\nIn order to avoid this, the authors proposed to focus on maximising $$\\log(D(G(\\mathbf{z}))$$ Here as well $D(G(\\mathbf{z^{(i)}})) \\approx 0$, and similarly like our previous case, $$\\frac{dD(G(\\mathbf{z}))}{d\\hat{\\mathbf{y}}}=D(G(\\mathbf{z}))\\left[1-D(G(\\mathbf{z}))\\right]\\approx0$$ But, $$-\\frac{d\\log(D(G(\\mathbf{z})))}{dD(G(\\mathbf{z}))}=-\\frac{1}{D(G(\\mathbf{z}))}\\approx-\\infty$$ This result tending to $-\\infty$ can help offset the closeness to $0$ we get with $dD(G(\\mathbf{z}))/d\\hat{\\mathbf{y}}$ when we apply the chain rule, thus providing overall stronger gradients for our generator to learn with.\nA more intuitive explanation: As discussed before $1-D(G(\\mathbf{z}))$ represents how fake the data is. So instead of the generator minimising the probability of an image being fake to the discriminator, it focuses on maximising the probability of an image being real.\nNote: Also, note that in the original research paper, the authors suggested to train the discriminator for $k$ times and the generator $1$ time in an alternating fashion. They proposed $k$ to be a hyper-parameter and went with $k=1$.\nTheoretical Results Result 1 For a fixed $G$, the optimal discriminator $D$ is: $$D^{*}_G(\\mathbf{x})=\\frac{p_d(\\mathbf{x})}{p_d(\\mathbf{x})+p_g(\\mathbf{x})}$$ where, $p_d$ is the distribution of the data and $p_g$ is the distribution of the generator.\nProof. We have our loss function: $$L(G, D) = \\int \\left(p_{\\mathbf{d}}(\\mathbf{x}) \\log(D(\\mathbf{x})) + p_{\\mathbf{g}}(\\mathbf{x}) \\log(1 - D(\\mathbf{x})) \\right) \\, d\\mathbf{x}$$ where $\\mathbf{x}$ can be both, generated and real samples. This integral represents an expectation over the input space. If we can minimise the quantity inside the integral for each $\\mathbf{x}$, then the entire integral is minimised because the integral sums up these individual minima over all $\\mathbf{x}$.\nTherefore differentiating the quantity inside with $D(\\mathbf{x})$ and equating it to $0$:\n$\\Rightarrow \\frac{d}{dD(\\mathbf{x})} \\left( p_{\\mathbf{d}}(\\mathbf{x}) \\log(D(\\mathbf{x})) + p_{\\mathbf{g}}(\\mathbf{x}) \\log(1 - D(\\mathbf{x})) \\right) = 0$\n$\\Rightarrow \\frac{p_{\\mathbf{d}}(\\mathbf{x})}{D(\\mathbf{x})} - \\frac{p_{\\mathbf{g}}(\\mathbf{x})}{1 - D(\\mathbf{x})} = 0$\n$\\Rightarrow p_{\\mathbf{d}}(\\mathbf{x})(1 - D(\\mathbf{x})) = p_{\\mathbf{g}}(\\mathbf{x})D(\\mathbf{x})$\n$\\Rightarrow p_{\\mathbf{d}}(\\mathbf{x}) = D(\\mathbf{x})(p_{\\mathbf{d}}(\\mathbf{x}) + p_{\\mathbf{g}}(\\mathbf{x}))$\n$\\Rightarrow D^*(\\mathbf{x}) = \\frac{p_{\\mathbf{d}}(\\mathbf{x})}{p_{\\mathbf{d}}(\\mathbf{x}) + p_{\\mathbf{g}}(\\mathbf{x})}$\nReformulation Therefore, the main minmax game can be reformulated as: $$C(G)=\\max_D V(G,D)= \\mathbb{E}_{\\mathbf{x}\\sim p_{d}}[\\log D^*_G(\\mathbf{x})]+ \\mathbb{E}_{\\mathbf{x}\\sim p_{g}}[\\log(1-D^*_G(\\mathbf{x})]$$ Hence, through this we can say that the training objective of the discriminator is maximising the log likelihood of the conditional probability $P(Y=1|\\mathbf{x})$ when $\\mathbf{x}$ comes from $p_d$ and $P(Y=0|\\mathbf{x})$ when $\\mathbf{x}$ comes from $p_g$.\nNow, putting $D^{*}_G(\\mathbf{x})=\\frac{p_d(\\mathbf{x})}{p_d(\\mathbf{x})+p_g(\\mathbf{x})}$ in the above equation, we get $$C(G)= \\mathbb{E}_{\\mathbf{x}\\sim p_{d}}\\left[\\log \\frac{p_d(\\mathbf{x})}{p_d(\\mathbf{x})+p_g(\\mathbf{x})}\\right] + \\mathbb{E}_{\\mathbf{x}\\sim p_{g}}\\left[\\log\\frac{p_g(\\mathbf{x})}{p_d(\\mathbf{x})+p_g(\\mathbf{x})}\\right]$$ Result 2 The global minimum for training criterion of the generator $C(G)$ is achieved if and only if $p_g=p_d$. At that point, $C(G)$ takes a value $-\\log4$.\nProof. Given $$\\begin{aligned} C(G)\u0026=\\mathbb{E}_{\\mathbf{x}\\sim p_{d}}\\left[\\log \\frac{p_d(\\mathbf{x})}{p_d(\\mathbf{x})+p_g(\\mathbf{x})}\\right] + \\mathbb{E}_{\\mathbf{x}\\sim p_{g}}\\left[\\log\\frac{p_g(\\mathbf{x})}{p_d(\\mathbf{x})+p_g(\\mathbf{x})}\\right]\\\\ \u0026=\\mathbb{E}_{\\mathbf{x}\\sim p_{d}}\\left[\\log\\frac{1}{2}\\cdot\\frac{p_d(\\mathbf{x})}{\\frac{p_d(\\mathbf{x})+p_g(\\mathbf{x})}{2}}\\right] + \\mathbb{E}_{\\mathbf{x}\\sim p_{g}}\\left[\\log\\frac{1}{2}\\cdot\\frac{p_g(\\mathbf{x})}{\\frac{p_d(\\mathbf{x})+p_g(\\mathbf{x})}{2}}\\right]\\\\ \u0026=\\mathbb{E}_{\\mathbf{x}\\sim p_{d}}\\left[\\log\\frac{p_d(\\mathbf{x})}{\\frac{p_d(\\mathbf{x})+p_g(\\mathbf{x})}{2}}\\right] + \\mathbb{E}_{\\mathbf{x}\\sim p_{g}}\\left[\\log\\cdot\\frac{p_g(\\mathbf{x})}{\\frac{p_d(\\mathbf{x})+p_g(\\mathbf{x})}{2}}\\right] +2\\log\\frac{1}{2}\\\\ \u0026=-\\log4 + \\mathbb{E}_{\\mathbf{x}\\sim p_{d}}\\left[\\log\\frac{p_d(\\mathbf{x})}{\\frac{p_d(\\mathbf{x})+p_g(\\mathbf{x})}{2}}\\right] + \\mathbb{E}_{\\mathbf{x}\\sim p_{g}}\\left[\\log\\cdot\\frac{p_g(\\mathbf{x})}{\\frac{p_d(\\mathbf{x})+p_g(\\mathbf{x})}{2}}\\right] \\\\ \\end{aligned} $$ Therefore, $$C(G)=-\\log4 + KL\\left(p_d\\bigg|\\bigg|\\frac{p_d+p_g}{2}\\right) + KL\\left(p_g\\bigg|\\bigg|\\frac{p_d+p_g}{2}\\right)$$ where, $KL$ is the Kullback-Leibler divergence. The expression after $-\\log4$ is twice of the Jensen-Shannon divergence ($JSD$) between $p_g$ and $p_d$: $$C(G)=-\\log4+2\\cdot JSD(p_d||p_g)$$ Since $JSD$ between the two distributions is always non-negative, or zero only when they are equal. Therefore, $$C^*=-\\log4$$ and the only solution to this is $p_g=p_d$.\nWhen $p_g=p_d$, from result 1 we get $$D^{*}_G(\\mathbf{x})=\\frac{1}{2}$$ Therefore, from the reformulation in result 1 we get, $$C(G)=\\log\\frac{1}{2}+\\log\\frac{1}{2}=-\\log4$$ References (1) Ian Goodfellow et al. “Generative adversarial nets.” NIPS, 2014.\n(2) Alec Radford et al. “UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS.” ICLR 2016\n(3) Lilian Weng. (2017) “From GAN to WGAN”\n",
  "wordCount" : "1126",
  "inLanguage": "en",
  "datePublished": "2024-04-12T02:49:45+05:30",
  "dateModified": "2024-04-12T02:49:45+05:30",
  "author":[{
    "@type": "Person",
    "name": "Sasmit Datta"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://example.org/posts/gans/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Sasmit's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://example.org/favicon.ico"
    }
  }
}
</script>
    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '\\[', right: '\\]', display: true},   
        {left: '$$', right: '$$', display: true},     
        {left: '\\(', right: '\\)', display: false},  
        {left: '$', right: '$', display: false}
      ],
      throwOnError : false
    });
  });
</script>
    
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://example.org/" accesskey="h" title="Sasmit&#39;s Blog (Alt + H)">Sasmit&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Generative Adversarial Networks
    </h1>
    <div class="post-meta"><span title='2024-04-12 02:49:45 +0530 IST'>April 12, 2024</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Sasmit Datta

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a><ul>
                        
                <li>
                    <a href="#intuitive-explanation" aria-label="Intuitive Explanation">Intuitive Explanation</a></li>
                <li>
                    <a href="#mathematical-explanation" aria-label="Mathematical Explanation">Mathematical Explanation</a></li></ul>
                </li>
                <li>
                    <a href="#framework" aria-label="Framework">Framework</a><ul>
                        
                <li>
                    <a href="#why-does-this-work" aria-label="Why does this work?">Why does this work?</a></li></ul>
                </li>
                <li>
                    <a href="#training" aria-label="Training">Training</a><ul>
                        
                <li>
                    <a href="#algorithm" aria-label="Algorithm">Algorithm</a></li>
                <li>
                    <a href="#better-loss-for-generator" aria-label="Better Loss for Generator">Better Loss for Generator</a></li></ul>
                </li>
                <li>
                    <a href="#theoretical-results" aria-label="Theoretical Results">Theoretical Results</a><ul>
                        
                <li>
                    <a href="#result-1" aria-label="Result 1">Result 1</a></li>
                <li>
                    <a href="#reformulation" aria-label="Reformulation">Reformulation</a></li>
                <li>
                    <a href="#result-2" aria-label="Result 2">Result 2</a></li></ul>
                </li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h1>
<p>The main idea: To train generators using really good classifiers.</p>
<h2 id="intuitive-explanation">Intuitive Explanation<a hidden class="anchor" aria-hidden="true" href="#intuitive-explanation">#</a></h2>
<p>Imagine a counterfeiter tasked with creating fake paintings and a detective tasked with discerning fake from real paintings. Both of them are thrown in a game where they have to out compete each other. Through this, both of them will get have to get better in the methods they use to win the game.</p>
<h2 id="mathematical-explanation">Mathematical Explanation<a hidden class="anchor" aria-hidden="true" href="#mathematical-explanation">#</a></h2>
<p>There are two models: A generative model $G$ that tries to capture the data distribution and a discriminative model $D$ that estimates the probability of a particular sample came from the training data. Both $G$ and $D$ are put in this minimax adversarial game with a value function $V(G,D)$.</p>
<h1 id="framework">Framework<a hidden class="anchor" aria-hidden="true" href="#framework">#</a></h1>
<p>Both $G$ and $D$ are neural networks.</p>
<p>To learn $p_g$ which is the distribution of the generator&rsquo;s over data $\mathbf{x}$, we define a <strong>prior distribution</strong> $p_{\mathbf{z}}(\mathbf{z})$ where the input noise variable is sampled from. This is then mapped to the data space as $G(\mathbf{z};\theta_{g})$ where $G$ is a neural network with parameters $\theta_{g}$.</p>
<p>$D(\mathbf{x},\theta_d)$ on the other hand just outputs a single scaler ranging between $0$ and $1$ which represents the probability that the given piece of data is from our data distribution $p_d$ rather than $p_g$.</p>
<p>Here&rsquo;s the framework for training both of these neural nets:
</p>
$$\min_{G}\max_{D} V(G,D)=
\mathbb{E}_{\mathbf{x}\sim p_{data}}[\log D(\mathbf{x})]+
\mathbb{E}_{\mathbf{z}\sim p_{z}(\mathbf{z})}[\log(1-D(G(\mathbf{z})))]$$
<p>
One important observation can be made from this is that the generator doesn&rsquo;t directly &rsquo;look&rsquo; at the data. It tries to learn the distribution of it from just the &lsquo;feedback&rsquo; of the discriminator.</p>
<h2 id="why-does-this-work">Why does this work?<a hidden class="anchor" aria-hidden="true" href="#why-does-this-work">#</a></h2>
<p>What does $D$ predict?
</p>
$$D(\mathbf{x};\theta_d)=P(\mathbf{x}\textnormal{ is real})$$
<p>
So it&rsquo;s goal is to maximise,
</p>
$$\log D(\mathbf{x})$$
<p>
when the given sample is from the training set ($\mathbf{x}$ is a real data point). Conversely, the generators role is to minimise this as it&rsquo;s trying to fool the discriminator.</p>
<p>Similarly, the discriminator&rsquo;s goal is to maximise the second term when the data is from the generator.
</p>
$$\log(1-D(G(\mathbf{z})))$$
<p>
The term $1-D(G(\mathbf{z}))$ represents how fake the data is. So when the data is from the generator, the discriminator would want to maximise the log-likelihood of this term. Conversely, the generator would want to minimise this.</p>
<p>For training the generator we use the term,
</p>
$$-\log(D(G(\mathbf{z})))$$
<p>
is used instead of $\log(1-D(G(\mathbf{z})))$. The reason is covered in a later section.</p>
<h1 id="training">Training<a hidden class="anchor" aria-hidden="true" href="#training">#</a></h1>
<p>For training the adversarial net, discriminator is not started out fully trained. If so was the case, it would be hard for the generator to catch up. Instead, they are trained simultaneously with one step for optimising the discriminator and then one step for the generator.</p>
<h2 id="algorithm">Algorithm<a hidden class="anchor" aria-hidden="true" href="#algorithm">#</a></h2>
<hr>
<p><strong>for</strong> number of iterations <strong>do</strong></p>
<ul>
<li>Sample minibatch of $m$ noise samples $\set{\mathbf{z}^{(1)},\mathbf{z}^{(2)},&hellip;,\mathbf{z}^{(m)}}$ from noise prior $p_g(\mathbf{z})$.</li>
<li>Sample minibatch of $m$ data samples $\set{\mathbf{x}^{(1)},\mathbf{x}^{(2)},&hellip;,\mathbf{x}^{(m)}}$ from training set.</li>
<li>Update the discriminator by descending its stochastic gradient: $$\nabla_{\theta_d}\frac{1}{m}\sum_{i=1}^{m}\left[-\log D(\mathbf{x^{(i)}}) - \log(1-D(G(\mathbf{z^{(i)}})))\right]$$</li>
<li>Sample minibatch of $m$ noise samples $\set{\mathbf{z}^{(1)},\mathbf{z}^{(2)},&hellip;,\mathbf{z}^{(m)}}$ from noise prior $p_g(\mathbf{z})$.</li>
<li>Update the generator by descending its stochastic gradient: $$\nabla_{\theta_g}\frac{1}{m}\sum_{i=1}^{m}\left[\log(1-D(G(\mathbf{z^{(i)}})))\right]$$
end <strong>for</strong></li>
</ul>
<hr>
<h2 id="better-loss-for-generator">Better Loss for Generator<a hidden class="anchor" aria-hidden="true" href="#better-loss-for-generator">#</a></h2>
<p>In practice, the given algorithm may not provide sufficient gradient for the generator in the initial stages of training. Early in training, $D$ has an easier time in rejecting samples from the generator. Hence, $\log(1-D(G(\mathbf{z})))$ saturates because $D(G(\mathbf{z})) \approx 0$ causing the generator to receive weak gradient signals.</p>
<p>Going deeper into why,
</p>
$$\frac{d\log(1-D(G(\mathbf{z})))}{dD(G(\mathbf{z}))}=-\frac{1}{1-D(G(\mathbf{z}))}\approx-1 \space\space.$$
<p>
In the final layer of $D$, we apply <a href="Logistic%20Regression.md#Math#Formulation">sigmoid</a> to get a probability score
</p>
$$D(G(\mathbf{z}))=\sigma(\hat{\mathbf{y}}) \space\space,$$
<p>
where $\hat{\mathbf{y}}$ is the pre-activation prediction of our discriminator and $\sigma(x)$ is the sigmoid activation function. Taking the <a href="Logistic%20Regression.md#Math#Gradient%20Descent#Sigmoid">derivative</a>
</p>
$$\frac{dD(G(\mathbf{z}))}{d\hat{\mathbf{y}}}=\sigma(\hat{\mathbf{y}})(1-\sigma(\hat{\mathbf{y}}))=D(G(\mathbf{z}))\left[1-D(G(\mathbf{z}))\right] \space\space .$$
<p>
Since, $D(G(\mathbf{z})) \approx 0$,
</p>
$$\frac{dD(G(\mathbf{z}))}{d\hat{\mathbf{y}}}\approx0 \space\space.$$
<p>
This is a very weak gradient which can stunt training for our generator.</p>
<p>In order to avoid this, the authors proposed to focus on maximising
</p>
$$\log(D(G(\mathbf{z}))$$
<p>
Here as well $D(G(\mathbf{z^{(i)}})) \approx 0$, and similarly like our previous case,
</p>
$$\frac{dD(G(\mathbf{z}))}{d\hat{\mathbf{y}}}=D(G(\mathbf{z}))\left[1-D(G(\mathbf{z}))\right]\approx0$$
<p>
But,
</p>
$$-\frac{d\log(D(G(\mathbf{z})))}{dD(G(\mathbf{z}))}=-\frac{1}{D(G(\mathbf{z}))}\approx-\infty$$
<p>
This result tending to $-\infty$ can help offset the closeness to $0$ we get with $dD(G(\mathbf{z}))/d\hat{\mathbf{y}}$ when we apply the chain rule, thus providing overall stronger gradients for our generator to learn with.</p>
<p><strong>A more intuitive explanation:</strong>
As discussed before $1-D(G(\mathbf{z}))$ represents how fake the data is. So instead of the generator minimising the probability of an image being fake to the discriminator, it focuses on maximising the probability of an image being real.</p>
<p><strong>Note:</strong>
Also, note that in the original research paper, the authors suggested to train the discriminator for $k$ times and the generator $1$ time in an alternating fashion. They proposed $k$ to be a hyper-parameter and went with $k=1$.</p>
<h1 id="theoretical-results">Theoretical Results<a hidden class="anchor" aria-hidden="true" href="#theoretical-results">#</a></h1>
<h2 id="result-1">Result 1<a hidden class="anchor" aria-hidden="true" href="#result-1">#</a></h2>
<p><em>For a fixed $G$, the optimal discriminator $D$ is:</em>
</p>
$$D^{*}_G(\mathbf{x})=\frac{p_d(\mathbf{x})}{p_d(\mathbf{x})+p_g(\mathbf{x})}$$
<p>
where, $p_d$ is the distribution of the data and $p_g$ is the distribution of the generator.</p>
<p><em>Proof.</em>
We have our loss function:
</p>
$$L(G, D) = \int \left(p_{\mathbf{d}}(\mathbf{x}) \log(D(\mathbf{x})) + p_{\mathbf{g}}(\mathbf{x}) \log(1 - D(\mathbf{x})) \right) \, d\mathbf{x}$$
<p>
where $\mathbf{x}$ can be both, generated and real samples. This integral represents an expectation over the input space. If we can minimise the quantity inside the integral for each $\mathbf{x}$, then the entire integral is minimised because the integral sums up these individual minima over all $\mathbf{x}$.</p>
<p>Therefore differentiating the quantity inside with $D(\mathbf{x})$ and equating it to $0$:</p>
<p>$\Rightarrow \frac{d}{dD(\mathbf{x})} \left( p_{\mathbf{d}}(\mathbf{x}) \log(D(\mathbf{x})) + p_{\mathbf{g}}(\mathbf{x}) \log(1 - D(\mathbf{x})) \right) = 0$</p>
<p>$\Rightarrow \frac{p_{\mathbf{d}}(\mathbf{x})}{D(\mathbf{x})} - \frac{p_{\mathbf{g}}(\mathbf{x})}{1 - D(\mathbf{x})} = 0$</p>
<p>$\Rightarrow p_{\mathbf{d}}(\mathbf{x})(1 - D(\mathbf{x})) = p_{\mathbf{g}}(\mathbf{x})D(\mathbf{x})$</p>
<p>$\Rightarrow p_{\mathbf{d}}(\mathbf{x}) = D(\mathbf{x})(p_{\mathbf{d}}(\mathbf{x}) + p_{\mathbf{g}}(\mathbf{x}))$</p>
<p>$\Rightarrow D^*(\mathbf{x}) = \frac{p_{\mathbf{d}}(\mathbf{x})}{p_{\mathbf{d}}(\mathbf{x}) + p_{\mathbf{g}}(\mathbf{x})}$</p>
<h2 id="reformulation">Reformulation<a hidden class="anchor" aria-hidden="true" href="#reformulation">#</a></h2>
<p>Therefore, the main minmax game can be reformulated as:
</p>
$$C(G)=\max_D V(G,D)=
\mathbb{E}_{\mathbf{x}\sim p_{d}}[\log D^*_G(\mathbf{x})]+
\mathbb{E}_{\mathbf{x}\sim p_{g}}[\log(1-D^*_G(\mathbf{x})]$$
<p>
Hence, through this we can say that the training objective of the discriminator is maximising the log likelihood of the conditional probability $P(Y=1|\mathbf{x})$ when $\mathbf{x}$ comes from $p_d$ and $P(Y=0|\mathbf{x})$ when $\mathbf{x}$ comes from $p_g$.</p>
<p>Now, putting $D^{*}_G(\mathbf{x})=\frac{p_d(\mathbf{x})}{p_d(\mathbf{x})+p_g(\mathbf{x})}$ in the above equation, we get
</p>
$$C(G)=
\mathbb{E}_{\mathbf{x}\sim p_{d}}\left[\log \frac{p_d(\mathbf{x})}{p_d(\mathbf{x})+p_g(\mathbf{x})}\right]
+
\mathbb{E}_{\mathbf{x}\sim p_{g}}\left[\log\frac{p_g(\mathbf{x})}{p_d(\mathbf{x})+p_g(\mathbf{x})}\right]$$
<h2 id="result-2">Result 2<a hidden class="anchor" aria-hidden="true" href="#result-2">#</a></h2>
<p><em>The global minimum for training criterion of the generator $C(G)$ is achieved if and only if $p_g=p_d$. At that point, $C(G)$ takes a value $-\log4$.</em></p>
<p><em>Proof.</em>
Given
</p>
$$\begin{aligned} 
C(G)&=\mathbb{E}_{\mathbf{x}\sim p_{d}}\left[\log \frac{p_d(\mathbf{x})}{p_d(\mathbf{x})+p_g(\mathbf{x})}\right]
+
\mathbb{E}_{\mathbf{x}\sim p_{g}}\left[\log\frac{p_g(\mathbf{x})}{p_d(\mathbf{x})+p_g(\mathbf{x})}\right]\\
&=\mathbb{E}_{\mathbf{x}\sim p_{d}}\left[\log\frac{1}{2}\cdot\frac{p_d(\mathbf{x})}{\frac{p_d(\mathbf{x})+p_g(\mathbf{x})}{2}}\right]
+
\mathbb{E}_{\mathbf{x}\sim p_{g}}\left[\log\frac{1}{2}\cdot\frac{p_g(\mathbf{x})}{\frac{p_d(\mathbf{x})+p_g(\mathbf{x})}{2}}\right]\\
&=\mathbb{E}_{\mathbf{x}\sim p_{d}}\left[\log\frac{p_d(\mathbf{x})}{\frac{p_d(\mathbf{x})+p_g(\mathbf{x})}{2}}\right]
+
\mathbb{E}_{\mathbf{x}\sim p_{g}}\left[\log\cdot\frac{p_g(\mathbf{x})}{\frac{p_d(\mathbf{x})+p_g(\mathbf{x})}{2}}\right]
+2\log\frac{1}{2}\\
&=-\log4 +
\mathbb{E}_{\mathbf{x}\sim p_{d}}\left[\log\frac{p_d(\mathbf{x})}{\frac{p_d(\mathbf{x})+p_g(\mathbf{x})}{2}}\right]
+
\mathbb{E}_{\mathbf{x}\sim p_{g}}\left[\log\cdot\frac{p_g(\mathbf{x})}{\frac{p_d(\mathbf{x})+p_g(\mathbf{x})}{2}}\right]
\\
\end{aligned}
$$
<p>
Therefore,
</p>
$$C(G)=-\log4 + KL\left(p_d\bigg|\bigg|\frac{p_d+p_g}{2}\right) + KL\left(p_g\bigg|\bigg|\frac{p_d+p_g}{2}\right)$$
<p>
where, $KL$ is the Kullback-Leibler divergence. The expression after $-\log4$ is twice of the Jensen-Shannon divergence ($JSD$) between $p_g$ and $p_d$:
</p>
$$C(G)=-\log4+2\cdot JSD(p_d||p_g)$$
<p>
Since $JSD$ between the two distributions is always non-negative, or zero only when they are equal. Therefore,
</p>
$$C^*=-\log4$$
<p>
and the only solution to this is $p_g=p_d$.</p>
<p>When $p_g=p_d$, from result 1 we get
</p>
$$D^{*}_G(\mathbf{x})=\frac{1}{2}$$
<p>
Therefore, from the reformulation in result 1 we get,
</p>
$$C(G)=\log\frac{1}{2}+\log\frac{1}{2}=-\log4$$
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p>(1) Ian Goodfellow et al. <a href="https://arxiv.org/pdf/1406.2661.pdf">“Generative adversarial nets.”</a> NIPS, 2014.</p>
<p>(2) Alec Radford et al. <a href="https://arxiv.org/pdf/1511.06434.pdf">&ldquo;UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS.&rdquo;</a> ICLR 2016</p>
<p>(3) Lilian Weng. (2017) <a href="https://lilianweng.github.io/posts/2017-08-20-gan/#:~:text=The%20loss%20function%20of%20the,a%20much%20smoother%20value%20space.">&ldquo;From GAN to WGAN&rdquo;</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Generative Adversarial Networks on x"
            href="https://x.com/intent/tweet/?text=Generative%20Adversarial%20Networks&amp;url=https%3a%2f%2fexample.org%2fposts%2fgans%2f&amp;hashtags=">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Generative Adversarial Networks on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fexample.org%2fposts%2fgans%2f&amp;title=Generative%20Adversarial%20Networks&amp;summary=Generative%20Adversarial%20Networks&amp;source=https%3a%2f%2fexample.org%2fposts%2fgans%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Generative Adversarial Networks on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fexample.org%2fposts%2fgans%2f&title=Generative%20Adversarial%20Networks">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Generative Adversarial Networks on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fexample.org%2fposts%2fgans%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Generative Adversarial Networks on whatsapp"
            href="https://api.whatsapp.com/send?text=Generative%20Adversarial%20Networks%20-%20https%3a%2f%2fexample.org%2fposts%2fgans%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Generative Adversarial Networks on telegram"
            href="https://telegram.me/share/url?text=Generative%20Adversarial%20Networks&amp;url=https%3a%2f%2fexample.org%2fposts%2fgans%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Generative Adversarial Networks on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Generative%20Adversarial%20Networks&u=https%3a%2f%2fexample.org%2fposts%2fgans%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://example.org/">Sasmit&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>






